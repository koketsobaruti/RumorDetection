{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae7258-a644-4bd2-9599-835cac3dc3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f069e9b7-383c-46ae-81b0-b90bb3fc81ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from scikeras) (3.3.3)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from scikeras) (1.4.2)\n",
      "Requirement already satisfied: absl-py in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from rich->keras>=3.2.0->scikeras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45ba0b5-f1ad-42e7-8821-4e26c39e0b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization==1.4.1\n",
      "  Downloading bayesian_optimization-1.4.1-py3-none-any.whl.metadata (508 bytes)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from bayesian-optimization==1.4.1) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from bayesian-optimization==1.4.1) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from bayesian-optimization==1.4.1) (1.4.2)\n",
      "Collecting colorama (from bayesian-optimization==1.4.1)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.1) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.1) (3.5.0)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'bayesian-optimization' candidate (version 1.4.1 at https://files.pythonhosted.org/packages/86/71/57ce5c1859e997b6a66fd368fcd940452032c7fb2208371117a693e5f70a/bayesian_optimization-1.4.1-py3-none-any.whl (from https://pypi.org/simple/bayesian-optimization/))\n",
      "Reason for being yanked: https://github.com/fmfn/BayesianOptimization/pull/388\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading bayesian_optimization-1.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: colorama, bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.4.1 colorama-0.4.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bayesian-optimization==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bbe5b1-7176-42e4-a798-4496b0d8c676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 12:27:24.217956: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-06 12:27:24.325081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 12:27:24.375563: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 12:27:24.389425: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-06 12:27:24.481118: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-06 12:27:25.290496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/sct/my_project_dir/my_project_env/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Input, Concatenate, Conv1D, GlobalMaxPooling1D, Flatten, Lambda, Reshape\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLu = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e773e1-ceba-4e9c-92dc-bbf28976c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8444a-53c3-4c01-bf39-b8a17eb9afdc",
   "metadata": {},
   "source": [
    "# Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04436c39-ae78-4726-a13c-0f3dfbbe0c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>label</th>\n",
       "      <th>time_delay (min)</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>difference</th>\n",
       "      <th>weight</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reports of \"moving body\" amidst #Germanwings w...</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>337960</td>\n",
       "      <td>6384</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREAKING:148passengers were on board #GermanWi...</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>52815</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING: #Germanwings crash victims include 7...</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>893549</td>\n",
       "      <td>2312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.1333</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.722</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>6.666667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: 148 feared dead in crashed #Germanwi...</td>\n",
       "      <td>167</td>\n",
       "      <td>32</td>\n",
       "      <td>418641</td>\n",
       "      <td>1859</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5167</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.8176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible news... Airbus A320 from Barcelona to...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>11062</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3667</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.829</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  retweet_count  \\\n",
       "0  Reports of \"moving body\" amidst #Germanwings w...             38   \n",
       "1  BREAKING:148passengers were on board #GermanWi...             43   \n",
       "2  BREAKING: #Germanwings crash victims include 7...             31   \n",
       "3  BREAKING: 148 feared dead in crashed #Germanwi...            167   \n",
       "4  Terrible news... Airbus A320 from Barcelona to...             26   \n",
       "\n",
       "   favorite_count  followers_count  friends_count  verified  label  \\\n",
       "0              15           337960           6384         1      1   \n",
       "1              15            52815            293         0      1   \n",
       "2               5           893549           2312         1      1   \n",
       "3              32           418641           1859         1      1   \n",
       "4               1            11062            233         0      1   \n",
       "\n",
       "   time_delay (min)  neg_sent  pos_sent  neu_sent  comp_sent  difference  \\\n",
       "0            1.2833     0.000      0.00     1.000     0.0000         0.0   \n",
       "1            1.5000     0.000      0.14     0.860     0.3818         1.0   \n",
       "2            4.1333     0.278      0.00     0.722    -0.6124        -0.2   \n",
       "3            3.5167     0.517      0.00     0.483    -0.8176         0.0   \n",
       "4            3.3667     0.171      0.00     0.829    -0.4767         0.0   \n",
       "\n",
       "   weight         ratio  \n",
       "0     0.0  1.000000e+00  \n",
       "1     1.0  1.000000e+10  \n",
       "2    -0.2  6.666667e-01  \n",
       "3     0.0  1.000000e+00  \n",
       "4     0.0  1.000000e+00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('updated_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aedf05e-61f4-4479-b8dc-8d0ab0f742c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text          0\n",
       "retweet_count       0\n",
       "favorite_count      0\n",
       "followers_count     0\n",
       "friends_count       0\n",
       "verified            0\n",
       "label               0\n",
       "time_delay (min)    0\n",
       "neg_sent            0\n",
       "pos_sent            0\n",
       "neu_sent            0\n",
       "comp_sent           0\n",
       "difference          0\n",
       "weight              0\n",
       "ratio               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf3acc-f6d9-4e5b-9774-1ab2b09ac826",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112bbc24-e1ca-4dd3-8ea7-b941a8e83ef2",
   "metadata": {},
   "source": [
    "## All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c5c623-8203-4e95-b2b9-5cf694bcce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = data['tweet_text'].values\n",
    "numerical_data = data[['retweet_count', 'followers_count', 'verified',\n",
    "                           'time_delay (min)', 'neg_sent', 'pos_sent', \n",
    "                       'neu_sent', 'comp_sent', 'difference', 'ratio']].values\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdea4baa-6f98-4e9a-bacf-2e6ede202269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we added stratifying sampling\n",
    "X_train_text, X_test_text, X_train_num, X_test_num, y_train, y_test = train_test_split(text_data, numerical_data, y, \n",
    "                                                                                       test_size=0.2, \n",
    "                                                                                       random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01caa8f5-7ed5-48cf-81b9-61cdcbd9749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train text: 4641\n",
      "Train number: 4641\n",
      "Test text: 1161\n",
      "Test number:1161\n",
      "Y Training: 4641\n",
      "Y Testing:1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of all the datasets\n",
    "print(f'Train text: {len(X_train_text)}'), print(f'Train number: {len(X_train_num)}')\n",
    "print(f'Test text: {len(X_test_text)}'), print(f'Test number:{len(X_test_num)}')\n",
    "print(f'Y Training: {len(y_train)}'), print(f'Y Testing:{len(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700874cd-e7e7-43c4-b662-8498e61dacff",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49b364-b00b-4fa5-a099-ac8703ec6531",
   "metadata": {},
   "source": [
    "## Normalizing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef20659-7976-4556-9c37-483737a7d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Use CPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0860bd2-c3ba-4ea6-a0d3-932fd2ceb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ELMo from Tensorflow\n",
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def4eff2-e919-4a6d-9bfb-035cc1e74318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to create word embeddings using ELMo \n",
    "def elmo_embeddings(text_list):\n",
    "    embeddings = elmo.signatures['default'](tf.constant(text_list))['elmo']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a894705-f9f9-4ad6-80b4-b9014a347ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_in_batches(texts, batch_size=32):\n",
    "    elmo_embed_np = []\n",
    "    total_batches = (len(texts) + batch_size - 1) // batch_size  # Calculate total number of batches\n",
    "    with tqdm(total=total_batches, desc='Processing Batches') as pbar:\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            batch_embeddings = elmo_embeddings(batch_texts)\n",
    "            # Average the embeddings for each text\n",
    "            batch_embeddings_np = [np.mean(embed.numpy(), axis=0) for embed in batch_embeddings]\n",
    "            for embed in batch_embeddings_np:\n",
    "                if embed.shape != (1024,):\n",
    "                    print(f\"Unexpected shape found: {embed.shape}\")\n",
    "            elmo_embed_np.extend(batch_embeddings_np)\n",
    "            pbar.update(1)  # Update progress bar\n",
    "    return np.array(elmo_embed_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4252cc4c-b540-4a85-a46d-67a830cd4a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|█████████████████████| 291/291 [03:49<00:00,  1.27it/s]\n",
      "Processing Batches: 100%|███████████████████████| 73/73 [00:57<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process ELMo embeddings in batches\n",
    "train_elmo_embed_np = process_in_batches(X_train_text, batch_size=16)  # Adjust batch size as needed\n",
    "test_elmo_embed_np = process_in_batches(X_test_text, batch_size=16)  # Adjust batch size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3813328-162f-4e46-8107-7797ee01c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_elmo_embed_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "975cb172-2fc7-4bd9-a73e-ff50df141085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4641, 1024)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_elmo_embed_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab96cc58-e592-43af-bb34-bf6591729613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value of training: -2.2559733390808105\n",
      "Maximum value of training: 2.334711790084839\n"
     ]
    }
   ],
   "source": [
    "print(f'Minimum value of training: {train_elmo_embed_np.min()}')\n",
    "print(f'Maximum value of training: {train_elmo_embed_np.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17b83379-81d4-4627-a1a1-c36c5d841beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161, 1024)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_elmo_embed_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12db4eb-94b5-4691-a836-7ccf28a46bc7",
   "metadata": {},
   "source": [
    "## Normalizing Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f7bdec8-d1be-4cfe-88e4-0c0a840d119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5fc7b40-057c-44c6-a259-35d2056ab726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using custom range\n",
    "class CustomMinMaxScaler:\n",
    "    def __init__(self, feature_range=(-2, 2)):\n",
    "        self.feature_range = feature_range\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # Fit the scaler to the data\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Transform the data to [0, 1] range\n",
    "        X_normalized = self.scaler.transform(X)\n",
    "        # Scale to the desired range [-2, 2]\n",
    "        a, b = self.feature_range\n",
    "        X_scaled = a + (X_normalized * (b - a))\n",
    "        return X_scaled\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        # Fit and transform the data\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7d4df36-09cc-478a-8b5d-38c07127cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized test shape: (1161, 10)\n"
     ]
    }
   ],
   "source": [
    "num_scaler = CustomMinMaxScaler(feature_range=(-2, 2))\n",
    "\n",
    "train_norm_num_features = num_scaler.fit_transform(X_train_num)\n",
    "test_norm_num_features = num_scaler.fit_transform(X_test_num)\n",
    "print(f'Normalized test shape: {test_norm_num_features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ca1cc13-c3f2-4504-9225-39873e9b5811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value of training: -2.0\n",
      "Maximum value of training: 2.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Minimum value of training: {train_norm_num_features.min()}')\n",
    "print(f'Maximum value of training: {test_norm_num_features.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4b595-15af-4718-bb53-41593c6e8489",
   "metadata": {},
   "source": [
    "## Concatenate Normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135d7b89-3565-40d2-a5e7-a0fcce7f27e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4641, 1034)\n",
      "Test shape: (1161, 1034)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.hstack((train_elmo_embed_np, train_norm_num_features))\n",
    "X_test = np.hstack((test_elmo_embed_np, test_norm_num_features))\n",
    "\n",
    "print(f'Train shape: {X_train.shape}')\n",
    "print(f'Test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dde575c6-0488-4f2f-8723-1344dc8adfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(neurons, learning_rate, batch_size,epochs,\n",
    "                  conv_layers, conv_filters, conv_kernel_size, \n",
    "                  dense_layers, normalization, dropout, dropout_rate):\n",
    "\n",
    "    ## build model architecture\n",
    "    input_x = Input(shape=(1034,))\n",
    "\n",
    "    ## Reshape to fit Conv1D input\n",
    "    x = Reshape((input_x.shape[1], 1))(input_x)\n",
    "\n",
    "    ## Define Convolutional Layers\n",
    "    for i in range(conv_layers):\n",
    "        x = Conv1D(filters=conv_filters, kernel_size=conv_kernel_size, activation='relu')(x)\n",
    "        if normalization > 0.5:\n",
    "            x = BatchNormalization()(x)\n",
    "                \n",
    "    ## apply pooling to the given output x\n",
    "    x = MaxPooling1D(pool_size=pool_size)(x)\n",
    "\n",
    "    ## flatten the layer \n",
    "    x = Flatten()(x)\n",
    "        \n",
    "    ## Define dense layers\n",
    "    for i in range(dense_layers):\n",
    "        x = Dense(neurons, activation='relu')(x)\n",
    "    \n",
    "        if dropout>0.5:\n",
    "            x = Dropout(dropout_rate, seed=123)(x)\n",
    "\n",
    "    ## Define an output layer where the final prediction is made\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "    ## Define the model\n",
    "    model = Model(inputs=input_x, outputs = output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate = learning_rate),\n",
    "                      metrics=['accuracy', 'recall', 'Precision', 'FalseNegatives'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63dab4-511e-4ca7-a101-03904b097ee7",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c93fcd09-b6a8-45b5-bcf3-88f1e14e4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4641, 1034)\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47dfb5fe-2874-42b0-9a1e-fd8ba1b6f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [10, 20],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'filters': [32, 64],\n",
    "    'kernel_size': [3, 5],\n",
    "    'pool_size': [2, 3],\n",
    "    'activation': ['relu', 'tanh']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bc8c672-741e-4a75-a7e9-d7603add570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "def cnn_model(lr=0.001, filters=64, kernel_size=3, pool_size=2,\n",
    "              num_conv_layers = 1, num_dense_layers=1, rate=0.5, units=64):\n",
    "    model = Sequential()\n",
    "    # Add convolutional layers\n",
    "    for _ in range(num_conv_layers):\n",
    "        model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', input_shape=(1034, 1)))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate = lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e72940f-6356-4b3c-98f0-94e144ea54f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('batch_size', 26),\n",
       "             ('epochs', 30),\n",
       "             ('filters', 44),\n",
       "             ('kernel_size', 4),\n",
       "             ('lr', 0.0017702277771397554),\n",
       "             ('num_conv_layers', 1),\n",
       "             ('num_dense_layers', 1),\n",
       "             ('pool_size', 2),\n",
       "             ('rate', 0.5),\n",
       "             ('units', 94)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from keras.layers import MaxPooling1D\n",
    "# Define KerasClassifier with build_fn\n",
    "model = KerasClassifier(build_fn=cnn_model, verbose=0, lr = [0.0001, 0.001, 0.01, 0.1], filters = [32, 64, 128],\n",
    "                        kernel_size = [3, 5], pool_size = [2, 3], num_conv_layers = [1, 2, 3], \n",
    "                        num_dense_layers = [1, 2, 3], rate = [0.2, 0.3, 0.4, 0.5], units = [64, 128, 256])\n",
    "\n",
    "# Define the grid search parameters\n",
    "lr = [0.001, 0.01]\n",
    "batch_size = [16, 32]\n",
    "epochs = [10, 20, 30]\n",
    "filters = [32, 64]\n",
    "kernel_size = [3, 5]\n",
    "pool_size = [2, 3]\n",
    "num_conv_layers = [1, 2, 3]\n",
    "num_dense_layers = [1, 2, 3]\n",
    "rate = [0.3, 0.4, 0.5]\n",
    "units = [64, 128]\n",
    "# Define the search space for Bayesian optimization\n",
    "# Define the grid search parameters\n",
    "param_grid = dict(\n",
    "    lr=lr,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    filters=filters,\n",
    "    kernel_size=kernel_size,\n",
    "    pool_size=pool_size,\n",
    "    num_conv_layers=num_conv_layers,\n",
    "    num_dense_layers=num_dense_layers,\n",
    "    rate=rate,\n",
    "    units=units\n",
    ")\n",
    "# Setup BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=param_grid,\n",
    "    n_iter=10,  # Number of iterations for Bayesian optimization\n",
    "    cv=10,  # Cross-validation folds\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "opt.fit(X_train, y_train)\n",
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d772281-2729-4cb7-8f05-dbbb856d82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "def cnn_model(lr, filters, kernel_size, pool_size,num_conv_layers, \n",
    "              num_dense_layers, rate, units):\n",
    "    model = Sequential()\n",
    "    # Add convolutional layers\n",
    "    for _ in range(num_conv_layers):\n",
    "        model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', input_shape=(1034, 1)))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate = lr), loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', 'recall', 'Precision', 'FalseNegatives'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b342c2ad-7f0b-485b-adaf-d9964f5c187b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.548832</td>\n",
       "      <td>0.114046</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.783247</td>\n",
       "      <td>0.808938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.454866</td>\n",
       "      <td>0.115286</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>0.793835</td>\n",
       "      <td>0.817104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.093937</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.842672</td>\n",
       "      <td>0.777070</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.825120</td>\n",
       "      <td>0.843031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.158407</td>\n",
       "      <td>0.115311</td>\n",
       "      <td>0.851293</td>\n",
       "      <td>0.751592</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.831508</td>\n",
       "      <td>0.850173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109.225554</td>\n",
       "      <td>0.115118</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.840679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105.807852</td>\n",
       "      <td>0.120733</td>\n",
       "      <td>0.834052</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.810690</td>\n",
       "      <td>0.831902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.070742</td>\n",
       "      <td>0.113466</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.856044</td>\n",
       "      <td>0.870690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>107.549362</td>\n",
       "      <td>0.114945</td>\n",
       "      <td>0.829741</td>\n",
       "      <td>0.803797</td>\n",
       "      <td>0.725714</td>\n",
       "      <td>0.814995</td>\n",
       "      <td>0.831655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>110.905580</td>\n",
       "      <td>0.114803</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.825041</td>\n",
       "      <td>0.841639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>104.537937</td>\n",
       "      <td>0.113840</td>\n",
       "      <td>0.851293</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>0.840054</td>\n",
       "      <td>0.853578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time  test_accuracy  test_recall  test_precision  \\\n",
       "0  108.548832    0.114046       0.812903     0.651899        0.762963   \n",
       "1  104.454866    0.115286       0.818966     0.694268        0.751724   \n",
       "2  105.093937    0.115513       0.842672     0.777070        0.762500   \n",
       "3  104.158407    0.115311       0.851293     0.751592        0.797297   \n",
       "4  109.225554    0.115118       0.844828     0.683544        0.830769   \n",
       "5  105.807852    0.120733       0.834052     0.708861        0.783217   \n",
       "6  108.070742    0.113466       0.870690     0.810127        0.810127   \n",
       "7  107.549362    0.114945       0.829741     0.803797        0.725714   \n",
       "8  110.905580    0.114803       0.840517     0.797468        0.750000   \n",
       "9  104.537937    0.113840       0.851293     0.860759        0.743169   \n",
       "\n",
       "   test_f1_macro  test_f1_weighted  \n",
       "0       0.783247          0.808938  \n",
       "1       0.793835          0.817104  \n",
       "2       0.825120          0.843031  \n",
       "3       0.831508          0.850173  \n",
       "4       0.818750          0.840679  \n",
       "5       0.810690          0.831902  \n",
       "6       0.856044          0.870690  \n",
       "7       0.814995          0.831655  \n",
       "8       0.825041          0.841639  \n",
       "9       0.840054          0.853578  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "batch_size=26\n",
    "epochs=30\n",
    "filters=44\n",
    "kernel_size=4\n",
    "lr=0.0017702277771397554\n",
    "num_conv_layers=1\n",
    "num_dense_layers=1\n",
    "pool_size= 2\n",
    "rate=0.5\n",
    "units=94\n",
    "scoring = ['accuracy', 'recall',  'precision','f1_macro', 'f1_weighted']\n",
    "def create_model():\n",
    "    return cnn_model(lr, filters, kernel_size, pool_size,num_conv_layers, \n",
    "              num_dense_layers, rate, units)\n",
    "# Define KerasClassifier with build_fn\n",
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "# Perform cross-validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "# score = cross_val_score(model, X_train, y_train, scoring=scoring, cv=kfold)\n",
    "scores = cross_validate(model, X_train, y_train, scoring=scoring, cv=kfold)\n",
    "cnn_cv_scores = pd.DataFrame(scores)\n",
    "display(cnn_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e735adf-8e0e-4d40-9765-084e2b5dceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_cv_scores.to_csv('cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "131ff174-ccc0-4590-bc23-0b4a743303f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.771748067907718 | Prec %: 77.17\n",
      "Recall: 0.7539385632508264  | Recall %: 75.39\n",
      "Accuracy: 0.8396954949944384  | Accuracy %: 83.97\n",
      "Macro F1: 0.8199282284817473  | Macro F1 %: 81.99\n",
      "Weighted F1: 0.8389387016941903  | Weighted F1 %: 83.89\n"
     ]
    }
   ],
   "source": [
    "avg_f1_macro_cv_score = cnn_cv_scores['test_f1_macro'].mean()\n",
    "avg_f1_weighted_cv_score = cnn_cv_scores['test_f1_weighted'].mean()\n",
    "avg_precision_cv_score = cnn_cv_scores['test_precision'].mean()\n",
    "avg_recall_cv_score = cnn_cv_scores['test_recall'].mean()\n",
    "avg_acc_cv_score = cnn_cv_scores['test_accuracy'].mean()\n",
    "\n",
    "acc_perc = round((avg_acc_cv_score * 100), 2)\n",
    "recall_perc = round((avg_recall_cv_score * 100), 2)\n",
    "precision_perc = round((avg_precision_cv_score * 100), 2)\n",
    "weighted_perc = round((avg_f1_weighted_cv_score * 100), 2)\n",
    "macro_perc = round((avg_f1_macro_cv_score * 100), 2)\n",
    "\n",
    "print(f'Precision: {avg_precision_cv_score}', f'| Prec %: {precision_perc}')\n",
    "print(f'Recall: {avg_recall_cv_score}', f' | Recall %: {recall_perc}')\n",
    "print(f'Accuracy: {avg_acc_cv_score}', f' | Accuracy %: {acc_perc}')\n",
    "print(f'Macro F1: {avg_f1_macro_cv_score}', f' | Macro F1 %: {macro_perc}')\n",
    "print(f'Weighted F1: {avg_f1_weighted_cv_score}', f' | Weighted F1 %: {weighted_perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1640636d-a389-428d-851b-2f95bc8b5c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,batch_size=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7d927b0-457b-4eea-bdec-c8034123c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.7617866004962779  | Test Set Accuracy %: 84.15\n",
      "Training Set Recall: 0.7772151898734178  | Test Set Recall %: 77.72\n",
      "Training Set Accuracy: 0.8415159345391904  | Test Set Precision %: 76.18\n",
      "Macro F1: 0.8243443253803802  | Test Macro F1 %: 82.43\n",
      "Weighted F1: 0.8418943722066021  | Test Weighted F1 %: 84.19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score, precision_score\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "test_recall = recall_score(y_test, y_test_predict)\n",
    "test_precision = precision_score(y_test, y_test_predict)\n",
    "\n",
    "test_acc_perc = round((test_accuracy * 100), 2)\n",
    "test_recall_perc = round((test_recall * 100), 2)\n",
    "test_precision_perc = round((test_precision * 100), 2)\n",
    "\n",
    "print(f'Test Precision: {test_precision}', f\" | Test Set Accuracy %: {test_acc_perc}\")\n",
    "print(f'Training Set Recall: {test_recall}', f' | Test Set Recall %: {test_recall_perc}')\n",
    "print(f\"Training Set Accuracy: {test_accuracy}\", f' | Test Set Precision %: {test_precision_perc}')\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "macrof1_score = f1_score(y_test, y_test_predict, average='macro')\n",
    "macro_perc = round((macrof1_score * 100), 2)\n",
    "print(f'Macro F1: {macrof1_score}',f' | Test Macro F1 %: {macro_perc}')\n",
    "\n",
    "wf1_score = f1_score(y_test, y_test_predict, average='weighted')\n",
    "weighted_perc = round((wf1_score * 100), 2)\n",
    "print(f'Weighted F1: {wf1_score}',f' | Test Weighted F1 %: {weighted_perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59eedb7-2b8f-4177-802a-b6df9e8b3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "dtree_model = DecisionTreeClassifier(max_depth=10, random_state=42) # Initialize a decision tree regressor\n",
    "scoring = ['accuracy', 'recall',  'precision','f1_macro', 'f1_weighted' ]\n",
    "scores = cross_validate(dtree_model, X_train, y_train, scoring=scoring, cv=10)\n",
    "dtree_cv_scores = pd.DataFrame(scores)\n",
    "display(dtree_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09977f24-399f-4ba9-9051-f70fec469605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - FalseNegatives: 306.7222 - Precision: 0.6674 - accuracy: 0.7428 - loss: 0.5458 - recall: 0.4684 - val_FalseNegatives: 102.0000 - val_Precision: 0.7655 - val_accuracy: 0.8127 - val_loss: 0.4177 - val_recall: 0.6973\n",
      "Epoch 2/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 214.7431 - Precision: 0.7432 - accuracy: 0.8133 - loss: 0.4184 - recall: 0.6620 - val_FalseNegatives: 106.0000 - val_Precision: 0.7938 - val_accuracy: 0.8213 - val_loss: 0.4103 - val_recall: 0.6855\n",
      "Epoch 3/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 183.0417 - Precision: 0.7640 - accuracy: 0.8316 - loss: 0.3743 - recall: 0.6967 - val_FalseNegatives: 81.0000 - val_Precision: 0.7552 - val_accuracy: 0.8235 - val_loss: 0.3976 - val_recall: 0.7596\n",
      "Epoch 4/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 182.3056 - Precision: 0.7702 - accuracy: 0.8255 - loss: 0.3838 - recall: 0.6976 - val_FalseNegatives: 87.0000 - val_Precision: 0.7764 - val_accuracy: 0.8288 - val_loss: 0.3891 - val_recall: 0.7418\n",
      "Epoch 5/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 162.4792 - Precision: 0.7905 - accuracy: 0.8512 - loss: 0.3393 - recall: 0.7510 - val_FalseNegatives: 69.0000 - val_Precision: 0.7204 - val_accuracy: 0.8138 - val_loss: 0.3900 - val_recall: 0.7953\n",
      "Epoch 6/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - FalseNegatives: 156.0833 - Precision: 0.7771 - accuracy: 0.8510 - loss: 0.3244 - recall: 0.7595 - val_FalseNegatives: 98.0000 - val_Precision: 0.8157 - val_accuracy: 0.8364 - val_loss: 0.4037 - val_recall: 0.7092\n",
      "Epoch 7/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 155.7153 - Precision: 0.8134 - accuracy: 0.8596 - loss: 0.3087 - recall: 0.7602 - val_FalseNegatives: 78.0000 - val_Precision: 0.7358 - val_accuracy: 0.8159 - val_loss: 0.3843 - val_recall: 0.7685\n",
      "Epoch 8/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 145.2431 - Precision: 0.8172 - accuracy: 0.8665 - loss: 0.2996 - recall: 0.7725 - val_FalseNegatives: 146.0000 - val_Precision: 0.8761 - val_accuracy: 0.8138 - val_loss: 0.4291 - val_recall: 0.5668\n",
      "Epoch 9/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 139.1319 - Precision: 0.8136 - accuracy: 0.8635 - loss: 0.2977 - recall: 0.7584 - val_FalseNegatives: 110.0000 - val_Precision: 0.8195 - val_accuracy: 0.8278 - val_loss: 0.3950 - val_recall: 0.6736\n",
      "Epoch 10/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - FalseNegatives: 123.8750 - Precision: 0.8562 - accuracy: 0.8863 - loss: 0.2562 - recall: 0.7904 - val_FalseNegatives: 82.0000 - val_Precision: 0.7544 - val_accuracy: 0.8224 - val_loss: 0.4037 - val_recall: 0.7567\n",
      "Epoch 11/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - FalseNegatives: 125.1597 - Precision: 0.8558 - accuracy: 0.8883 - loss: 0.2619 - recall: 0.7905 - val_FalseNegatives: 75.0000 - val_Precision: 0.7616 - val_accuracy: 0.8310 - val_loss: 0.4204 - val_recall: 0.7774\n",
      "Epoch 12/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - FalseNegatives: 114.8819 - Precision: 0.8600 - accuracy: 0.8938 - loss: 0.2537 - recall: 0.8222 - val_FalseNegatives: 94.0000 - val_Precision: 0.7788 - val_accuracy: 0.8245 - val_loss: 0.4218 - val_recall: 0.7211\n",
      "Epoch 13/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - FalseNegatives: 108.6111 - Precision: 0.8525 - accuracy: 0.8933 - loss: 0.2452 - recall: 0.8341 - val_FalseNegatives: 74.0000 - val_Precision: 0.7472 - val_accuracy: 0.8245 - val_loss: 0.3831 - val_recall: 0.7804\n",
      "Epoch 14/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - FalseNegatives: 99.0903 - Precision: 0.8835 - accuracy: 0.9092 - loss: 0.2116 - recall: 0.8469 - val_FalseNegatives: 80.0000 - val_Precision: 0.7741 - val_accuracy: 0.8332 - val_loss: 0.4178 - val_recall: 0.7626\n",
      "Epoch 15/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - FalseNegatives: 105.1389 - Precision: 0.8757 - accuracy: 0.9032 - loss: 0.2059 - recall: 0.8396 - val_FalseNegatives: 80.0000 - val_Precision: 0.8031 - val_accuracy: 0.8461 - val_loss: 0.4062 - val_recall: 0.7626\n",
      "Epoch 16/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - FalseNegatives: 76.6042 - Precision: 0.9137 - accuracy: 0.9324 - loss: 0.1780 - recall: 0.8928 - val_FalseNegatives: 67.0000 - val_Precision: 0.7438 - val_accuracy: 0.8278 - val_loss: 0.4433 - val_recall: 0.8012\n",
      "Epoch 17/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 87.6944 - Precision: 0.8849 - accuracy: 0.9183 - loss: 0.1821 - recall: 0.8558 - val_FalseNegatives: 81.0000 - val_Precision: 0.7877 - val_accuracy: 0.8385 - val_loss: 0.4543 - val_recall: 0.7596\n",
      "Epoch 18/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 76.5833 - Precision: 0.9241 - accuracy: 0.9337 - loss: 0.1607 - recall: 0.8732 - val_FalseNegatives: 92.0000 - val_Precision: 0.7778 - val_accuracy: 0.8256 - val_loss: 0.4490 - val_recall: 0.7270\n",
      "Epoch 19/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 93.3819 - Precision: 0.8906 - accuracy: 0.9156 - loss: 0.1818 - recall: 0.8487 - val_FalseNegatives: 61.0000 - val_Precision: 0.7500 - val_accuracy: 0.8353 - val_loss: 0.4770 - val_recall: 0.8190\n",
      "Epoch 20/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 81.5278 - Precision: 0.8853 - accuracy: 0.9193 - loss: 0.1815 - recall: 0.8755 - val_FalseNegatives: 82.0000 - val_Precision: 0.7681 - val_accuracy: 0.8288 - val_loss: 0.4830 - val_recall: 0.7567\n",
      "Epoch 21/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 69.2361 - Precision: 0.9121 - accuracy: 0.9353 - loss: 0.1576 - recall: 0.8910 - val_FalseNegatives: 76.0000 - val_Precision: 0.7587 - val_accuracy: 0.8288 - val_loss: 0.4670 - val_recall: 0.7745\n",
      "Epoch 22/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 71.1875 - Precision: 0.9041 - accuracy: 0.9303 - loss: 0.1551 - recall: 0.8856 - val_FalseNegatives: 87.0000 - val_Precision: 0.7812 - val_accuracy: 0.8310 - val_loss: 0.4755 - val_recall: 0.7418\n",
      "Epoch 23/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 70.2917 - Precision: 0.8945 - accuracy: 0.9295 - loss: 0.1632 - recall: 0.8854 - val_FalseNegatives: 60.0000 - val_Precision: 0.7328 - val_accuracy: 0.8267 - val_loss: 0.5308 - val_recall: 0.8220\n",
      "Epoch 24/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 61.5972 - Precision: 0.8965 - accuracy: 0.9317 - loss: 0.1568 - recall: 0.9013 - val_FalseNegatives: 123.0000 - val_Precision: 0.8594 - val_accuracy: 0.8299 - val_loss: 0.5462 - val_recall: 0.6350\n",
      "Epoch 25/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 72.2847 - Precision: 0.8922 - accuracy: 0.9265 - loss: 0.1661 - recall: 0.8795 - val_FalseNegatives: 82.0000 - val_Precision: 0.7846 - val_accuracy: 0.8364 - val_loss: 0.5230 - val_recall: 0.7567\n",
      "Epoch 26/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 70.1181 - Precision: 0.9225 - accuracy: 0.9374 - loss: 0.1399 - recall: 0.8875 - val_FalseNegatives: 94.0000 - val_Precision: 0.7839 - val_accuracy: 0.8267 - val_loss: 0.6536 - val_recall: 0.7211\n",
      "Epoch 27/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 65.8472 - Precision: 0.9122 - accuracy: 0.9337 - loss: 0.1604 - recall: 0.8884 - val_FalseNegatives: 61.0000 - val_Precision: 0.7023 - val_accuracy: 0.8084 - val_loss: 0.5656 - val_recall: 0.8190\n",
      "Epoch 28/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 76.3542 - Precision: 0.9061 - accuracy: 0.9292 - loss: 0.1623 - recall: 0.8791 - val_FalseNegatives: 75.0000 - val_Precision: 0.7661 - val_accuracy: 0.8332 - val_loss: 0.5740 - val_recall: 0.7774\n",
      "Epoch 29/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 72.9792 - Precision: 0.9246 - accuracy: 0.9359 - loss: 0.1444 - recall: 0.8820 - val_FalseNegatives: 72.0000 - val_Precision: 0.7615 - val_accuracy: 0.8332 - val_loss: 0.5449 - val_recall: 0.7864\n",
      "Epoch 30/30\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - FalseNegatives: 66.5833 - Precision: 0.9313 - accuracy: 0.9480 - loss: 0.1218 - recall: 0.9042 - val_FalseNegatives: 85.0000 - val_Precision: 0.8025 - val_accuracy: 0.8418 - val_loss: 0.5039 - val_recall: 0.7478\n"
     ]
    }
   ],
   "source": [
    "batch_size=26\n",
    "epochs=30\n",
    "filters=44\n",
    "kernel_size=4\n",
    "lr=0.0017702277771397554\n",
    "num_conv_layers=1\n",
    "num_dense_layers=1\n",
    "pool_size= 2\n",
    "rate=0.5\n",
    "units=94\n",
    "model = cnn_model(lr, filters, kernel_size, pool_size,num_conv_layers, \n",
    "              num_dense_layers, rate, units)\n",
    "\n",
    "history = model.fit(X_train, y_train,validation_split=0.2, epochs=30,batch_size=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03b7ef27-70db-4864-8772-3d3010a5be88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5184 candidates, totalling 51840 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Setup GridSearchCV\u001b[39;00m\n\u001b[1;32m     37\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid search parameters\n",
    "lr = [0.001, 0.01]\n",
    "batch_size = [16, 32]\n",
    "epochs = [10, 20, 30]\n",
    "filters = [32, 64]\n",
    "kernel_size = [3, 5]\n",
    "pool_size = [2, 3]\n",
    "num_conv_layers = [1, 2, 3]\n",
    "num_dense_layers = [1, 2, 3]\n",
    "rate = [0.3, 0.4, 0.5]\n",
    "units = [64, 128]\n",
    "\n",
    "# Define KerasClassifier with build_fn\n",
    "model = KerasClassifier(build_fn=cnn_model, verbose=0, lr = [0.001, 0.01], filters = [32, 64],\n",
    "                        kernel_size = [3, 5], pool_size = [2, 3], num_conv_layers = [1, 2, 3], \n",
    "                        num_dense_layers = [1, 2, 3], rate = [0.3, 0.4, 0.5], units = [64, 128])\n",
    "\n",
    "\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = dict(\n",
    "    lr=lr,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    filters=filters,\n",
    "    kernel_size=kernel_size,\n",
    "    pool_size=pool_size,\n",
    "    num_conv_layers=num_conv_layers,\n",
    "    num_dense_layers=num_dense_layers,\n",
    "    rate=rate,\n",
    "    units=units\n",
    ")\n",
    "# Setup GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, verbose=1)\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b0c5533-c51f-4eb4-ad74-cb73ded9bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'build_fn__lr': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [10, 20, 30, 40 , 50],\n",
    "    'build_fn__filters': [32, 64,128],\n",
    "    'build_fn__kernel_size': [3, 5],\n",
    "    'build_fn__pool_size': [2, 3],\n",
    "    'build_fn__num_conv_layers': [1, 2, 3],  # Number of Conv1D layers to test\n",
    "    'build_fn__num_dense_layers': [1, 2, 3],  # Number of Dense layers to test\n",
    "    'build_fn__rate': [0.2, 0.3, 0.4, 0.5],  # Dropout rates to test\n",
    "    'build_fn__units': [64, 128, 256]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb87d0b1-f888-4666-bd1d-8c314ff7c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 51840 candidates, totalling 518400 fits\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'set_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Create the KerasClassifier wrapper\u001b[39;00m\n\u001b[1;32m      5\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:883\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    876\u001b[0m score_params_test \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mscore_params, indices\u001b[38;5;241m=\u001b[39mtest)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;66;03m# here we clone the parameters, since sometimes the parameters\u001b[39;00m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# themselves might be estimators, e.g. when we search over different\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# estimators in a pipeline.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# ref: https://github.com/scikit-learn/scikit-learn/pull/26786\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    885\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    887\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:1171\u001b[0m, in \u001b[0;36mBaseWrapper.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1171\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;66;03m# Give a SciKeras specific user message to aid\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;66;03m# in moving from the Keras wrappers\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1176\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1177\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis issue can likely be resolved by setting this parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `estimator.get_params().keys()`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1182\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/base.py:291\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    288\u001b[0m         valid_params[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, sub_params \u001b[38;5;129;01min\u001b[39;00m nested_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mvalid_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msub_params)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'set_params'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the KerasClassifier wrapper\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, verbose=1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e258da3e-2500-4f28-8d95-1d69dc7d4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_def(neurons, activation, learning_rate, batch_size, \n",
    "              epochs, conv_layers, conv_filters, conv_kernel_size,\n",
    "             dense_layers, dropout, normalization, dropout_rate):\n",
    "    # Round numerical parameters to the nearest int\n",
    "    neurons = int(round(neurons))\n",
    "    batch_size = int(round(batch_size))\n",
    "    epochs = int(round(epochs))\n",
    "    conv_layers = int(round(conv_layers))\n",
    "    conv_filters = int(round(conv_filters))\n",
    "    print(conv_filters)\n",
    "    conv_kernel_size = int(round(conv_kernel_size))\n",
    "    dense_layers = int(round(dense_layers))\n",
    "\n",
    "    def create_model():\n",
    "        ## create model by passing the paramters\n",
    "        return cnn_model(neurons, activation, learning_rate, batch_size,epochs,\n",
    "                      conv_layers, conv_filters, conv_kernel_size, \n",
    "                      dense_layers, normalization, dropout, dropout_rate)\n",
    "    \n",
    "    return KerasClassifier(create_model, batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55f90f29-130a-427e-a4ad-4e6ab83ed9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54c5d72a-455a-4130-b492-daf271d7d725",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create KerasClassifier\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcnn_model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39m\u001b[43mparams_cnn\u001b[49m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m result \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, None]\n",
    "}\n",
    "scoring = ['accuracy', 'recall',  'precision','f1_macro', 'f1_weighted' ]\n",
    "# Create KerasClassifier\n",
    "model = KerasClassifier(build_fn=cnn_model, verbose=0)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params_cnn, cv=10, verbose=0, scoring='accuracy')\n",
    "result = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd3141-6098-4868-9431-458f8ea3e3a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Miscellenious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ea831e6-02d1-4415-b601-784b736800fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3e9e6ff-f28c-4aad-868f-335cc025d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ELMo model from TensorFlow Hub\n",
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b4cbec2-1042-4fde-a853-248cfb18d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer to handle ELMo embeddings\n",
    "def ElmoEmbedding(x):\n",
    "    def elmo_vectors(text):\n",
    "        return elmo.signatures['default'](tf.constant([text]))['elmo']\n",
    "\n",
    "    return tf.squeeze(elmo_vectors(tf.squeeze(tf.cast(x, tf.string))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0179c5ba-032c-45a2-a442-ca1d9ec2b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d97ef87-e4c7-4c5c-bff6-257bf7a6308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text_list):\n",
    "    embeddings = elmo_embeddings(text_list)\n",
    "    # Flatten embeddings if needed\n",
    "    embeddings_np = np.array([np.mean(embed.numpy(), axis=0) for embed in embeddings])\n",
    "    return embeddings_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3621630-3bc3-4cc7-87bf-f71d25f2d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_num_cnn(neurons, activation, optimizer, learning_rate, batch_size, epochs,\n",
    "                conv_layers, conv_filters, conv_kernel_size,\n",
    "                dense_layers, normalization, dropout, dropout_rate):\n",
    "    ## list and dictionary of several optimizers\n",
    "    optimizerL = ['SGD','Adam','RMSprop','Adadelta','Adagrad','Adamax','Nadam','Ftrl']\n",
    "    optimizerD = {'SGD':SGD(learning_rate = learning_rate),\n",
    "                  'Adam':Adam(learning_rate = learning_rate),\n",
    "                  'RMSprop':RMSprop(learning_rate = learning_rate),\n",
    "                  'Adadelta':Adadelta(learning_rate = learning_rate),\n",
    "                  'Adagrad':Adagrad(learning_rate = learning_rate),\n",
    "                  'Adamax':Adamax(learning_rate = learning_rate),\n",
    "                  'Nadam':Nadam(learning_rate = learning_rate),\n",
    "                  'Ftrl':Ftrl(learning_rate = learning_rate)}\n",
    "\n",
    "    ## list of activation function\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential']\n",
    "\n",
    "\n",
    "    #set variables by getting the next int \n",
    "    neurons = round(neurons)\n",
    "    # this is to get the activation function being used or optimizer being used for\n",
    "    # a given iteration of parameter se;ection\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    learning_rate = round(learning_rate)\n",
    "    epochs = round(epochs)\n",
    "    conv_layers = round(conv_layers)\n",
    "    conv_filters = round(conv_filters)\n",
    "    conv_kernel_size = round(conv_kernel_size)\n",
    "    dense_layers = round(dense_layers)\n",
    "\n",
    "    ## build model architecture\n",
    "    ### Textual model\n",
    "    #### Define a text input layer that takes in a string of text\n",
    "    input_text = Input(shape=(1,), dtype=tf.string, name='input_text')\n",
    "    print(f\"Input text shape: {input_text.shape}\")\n",
    "    print(f'Type: {input_text}')\n",
    "    \n",
    "    # Obtain ELMo embeddings\n",
    "    # ELMo embedding layer\n",
    "    embedding = Lambda(ElmoEmbedding, output_shape=(1024, ))(input_text)\n",
    "    # elmo_model = hub.KerasLayer(\"https://tfhub.dev/google/elmo/3\", trainable=False)\n",
    "    # embedding = elmo_model(input_text)[\"default\"]\n",
    "    # print(f\"elmo shape: {embedding.shape}\")\n",
    "    # embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length)(input_text)\n",
    "        \n",
    "    # Flatten ELMo embeddings (if necessary)\n",
    "    x_text = Flatten()(embedding)\n",
    "    # print(f\"x_text shape after Flatten: {x_text.shape}\")\n",
    "    \n",
    "    ## build numerical model\n",
    "    x_numeric = Input(shape = (10, ), name=\"input_num\")\n",
    "\n",
    "    ## COncatenate the numerical and text models\n",
    "    x = Concatenate()([x_text, x_numeric])\n",
    "    print(f\"Concatenated model: {x.shape}\")\n",
    "    ## Reshape to fit Conv1D input\n",
    "    x = Reshape((x.shape[1], 1))(x)\n",
    "    print(f\"Concatenated model after reshape: {x.shape}\")\n",
    "    \n",
    "    ## Define Convolutional Layers\n",
    "    for i in range(conv_layers):\n",
    "        ### create a 1D-conv layers with given number of filters and kernel sizes and a given activation function \n",
    "        ### from the function list with input staring from the concatenated neurons\n",
    "        x = Conv1D(filters=conv_filters, kernel_size=conv_kernel_size, activation=activation)(x)\n",
    "        print(f\"Concatenated model after iteration {i+1}: {x.shape}\")\n",
    "        if normalization > 0.5:\n",
    "            x = BatchNormalization()(x)\n",
    "    ## apply pooling to the given output x\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    print(f\"Shape after GlobalMaxPooling1D layer {i + 1}: {x.shape}\")\n",
    "    ## flatten the layer \n",
    "    x = Flatten()(x)\n",
    "\n",
    "    ## Define dense layers\n",
    "    for i in range(dense_layers):\n",
    "        ### define dense layer with the given amout of neurons and activation function\n",
    "        x = Dense(neurons, activation=activation)(x)\n",
    "\n",
    "        if dropout>0.5:\n",
    "            x = Dropout(dropout_rate, seed=123)()\n",
    "\n",
    "    ## Define an output layer where the final prediction is made\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    ## Define the model\n",
    "    model = Model(inputs=[x_text, x_numeric], outputs = output)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy', 'recall', 'Precision', 'FalseNegatives'])\n",
    "\n",
    "\n",
    "    ## Add early stopping to prevent model from continuing to find optimal parameters after the 20th\n",
    "    es = EarlyStopping(monitor='accuracy', mode = 'max', verbose=0, patience=20)\n",
    "    nn = KerasClassifier(build_fn =model, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    kfold = StratifiedKFold(n_splits =5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, [X_train_text, train_norm_num_features], y_train, scoring='accuracy')\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e13f17-0caf-4d31-99eb-f07b6d75200a",
   "metadata": {},
   "source": [
    "# Optimization of CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f24a9ce-998f-4d15-bc79-71284ee5684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02130327-6fa3-49cd-ba3b-2ca90430301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def cnn_model(neurons, activation, optimizer, learning_rate, batch_size,epochs,\n",
    "                  conv_layers, conv_filters, conv_kernel_size, \n",
    "                  dense_layers, normalization, dropout, dropout_rate):\n",
    "\n",
    "        optimizer_instance = Adam(learning_rate = learning_rate)\n",
    "        ## build model architecture\n",
    "        input_x = Input(shape=(1034,))\n",
    "\n",
    "        ## Reshape to fit Conv1D input\n",
    "        x = Reshape((input_x.shape[1], 1))(input_x)\n",
    "\n",
    "        ## Define Convolutional Layers\n",
    "        for i in range(conv_layers):\n",
    "            ### create a 1D-conv layers with given number of filters and kernel sizes and a given activation function \n",
    "            ### from the function list with input staring from the concatenated neurons\n",
    "            x = Conv1D(filters=conv_filters, kernel_size=conv_kernel_size, activation=activation)(x)\n",
    "\n",
    "            if normalization > 0.5:\n",
    "                x = BatchNormalization()(x)\n",
    "                \n",
    "        ## apply pooling to the given output x\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "        ## flatten the layer \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        ## Define dense layers\n",
    "        for i in range(dense_layers):\n",
    "            ### define dense layer with the given amout of neurons and activation function\n",
    "            x = Dense(neurons, activation=activation)(x)\n",
    "    \n",
    "            if dropout>0.5:\n",
    "                x = Dropout(dropout_rate, seed=123)(x)\n",
    "\n",
    "        ## Define an output layer where the final prediction is made\n",
    "        output = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        ## Define the model\n",
    "        model = Model(inputs=input_x, outputs = output)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy', 'recall', 'Precision', 'FalseNegatives'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b0d6901-ca11-4eca-b88d-2c4b48421535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_num_cnn(neurons, activation, optimizer, learning_rate, batch_size, epochs,\n",
    "                 conv_layers, conv_filters, conv_kernel_size,\n",
    "                 dense_layers, normalization, dropout, dropout_rate):\n",
    "    \n",
    "    # Define lists and dictionaries for optimizers and activation functions\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential']\n",
    "    optimizerL = ['SGD','Adam','RMSprop','Adadelta','Adagrad','Adamax','Nadam','Ftrl']\n",
    "    optimizerD = {'SGD':SGD(learning_rate = learning_rate),\n",
    "                  'Adam':Adam(learning_rate = learning_rate),\n",
    "                  'RMSprop':RMSprop(learning_rate = learning_rate),\n",
    "                  'Adadelta':Adadelta(learning_rate = learning_rate),\n",
    "                  'Adagrad':Adagrad(learning_rate = learning_rate),\n",
    "                  'Adamax':Adamax(learning_rate = learning_rate),\n",
    "                  'Nadam':Nadam(learning_rate = learning_rate),\n",
    "                  'Ftrl':Ftrl(learning_rate = learning_rate)}\n",
    "\n",
    "    \n",
    "    # Convert indices to corresponding names and instantiate optimizer\n",
    "    activation = activationL[int(round(activation))]\n",
    "    optimizer_name = optimizerL[int(round(optimizer))]\n",
    "    optimizer_instance = Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    # Round numerical parameters\n",
    "    neurons = int(round(neurons))\n",
    "    batch_size = int(round(batch_size))\n",
    "    epochs = int(round(epochs))\n",
    "    conv_layers = int(round(conv_layers))\n",
    "    conv_filters = int(round(conv_filters))\n",
    "    conv_kernel_size = int(round(conv_kernel_size))\n",
    "    dense_layers = int(round(dense_layers))\n",
    "    \n",
    "    # Define the Keras model with the provided parameters\n",
    "    def create_model():\n",
    "        return cnn_model(\n",
    "            neurons=neurons,\n",
    "            activation=activation,\n",
    "            optimizer=optimizer_instance,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            conv_layers=conv_layers,\n",
    "            conv_filters=conv_filters,\n",
    "            conv_kernel_size=conv_kernel_size,\n",
    "            dense_layers=dense_layers,\n",
    "            normalization=normalization,\n",
    "            dropout=dropout,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "    \n",
    "    # Create KerasClassifier\n",
    "    model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # Define early stopping\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=kfold)\n",
    "    \n",
    "    score=np.nan_to_num(score)\n",
    "\n",
    "    score=score.mean()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ff5f3-21d0-43d9-8388-29c0be0e71ca",
   "metadata": {},
   "source": [
    "## Define the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a11bab0-d701-422b-b4cb-272b19950d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cnn = {\n",
    "    'neurons': (10, 100),           # Number of neurons in dense layers\n",
    "    'activation': (0, 7),           # Type of activation function\n",
    "    'optimizer': (0, 7),            # Optimization algorithm\n",
    "    'learning_rate': (0.001, 0.1),  # How fast the model learns\n",
    "    'batch_size': (16, 128),        # Number of samples used in each training step\n",
    "    'epochs': (10, 50),             # Number of times the model sees the entire dataset\n",
    "    'conv_layers': (1, 4),          # Number of layers that find patterns in data\n",
    "    'conv_filters': (32, 128),      # Number of different patterns each layer looks for\n",
    "    'conv_kernel_size': (3, 5),     # Size of the window that moves over the data\n",
    "    'dense_layers': (1, 3),         # Layers that process information after finding patterns\n",
    "    'dropout': (0.0, 0.5),\n",
    "    'normalization': (0.0, 1.0), # Technique to prevent overfitting\n",
    "    'dropout_rate': (0.1, 0.5)      # How much information is randomly ignored to prevent overfitting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbba023b-b390-4698-9082-63e5d5722d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_norm: (4641, 1034)\n",
      "Shape of y_train: (4641,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train_norm: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59af9941-ffed-4ce8-9844-5062407fe9d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... | conv_f... | conv_k... | conv_l... | dense_... |  dropout  | dropou... |  epochs   | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.285    \u001b[0m | \u001b[0m34.94    \u001b[0m | \u001b[0m73.86    \u001b[0m | \u001b[0m4.539    \u001b[0m | \u001b[0m1.886    \u001b[0m | \u001b[0m1.298    \u001b[0m | \u001b[0m0.01124  \u001b[0m | \u001b[0m0.2681   \u001b[0m | \u001b[0m19.55    \u001b[0m | \u001b[0m0.03443  \u001b[0m | \u001b[0m99.16    \u001b[0m | \u001b[0m0.2377   \u001b[0m | \u001b[0m0.5683   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.1059   \u001b[0m | \u001b[0m4.687    \u001b[0m | \u001b[0m85.58    \u001b[0m | \u001b[0m58.33    \u001b[0m | \u001b[0m3.932    \u001b[0m | \u001b[0m1.355    \u001b[0m | \u001b[0m1.148    \u001b[0m | \u001b[0m0.4504   \u001b[0m | \u001b[0m0.4176   \u001b[0m | \u001b[0m43.62    \u001b[0m | \u001b[0m0.08171  \u001b[0m | \u001b[0m99.19    \u001b[0m | \u001b[0m0.5773   \u001b[0m | \u001b[0m5.696    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.949    \u001b[0m | \u001b[0m19.07    \u001b[0m | \u001b[0m75.6     \u001b[0m | \u001b[0m3.211    \u001b[0m | \u001b[0m3.452    \u001b[0m | \u001b[0m2.395    \u001b[0m | \u001b[0m0.2826   \u001b[0m | \u001b[0m0.2097   \u001b[0m | \u001b[0m49.94    \u001b[0m | \u001b[0m0.01467  \u001b[0m | \u001b[0m65.39    \u001b[0m | \u001b[0m0.485    \u001b[0m | \u001b[0m2.835    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m5.095    \u001b[0m | \u001b[0m52.16    \u001b[0m | \u001b[0m70.45    \u001b[0m | \u001b[0m3.638    \u001b[0m | \u001b[0m3.842    \u001b[0m | \u001b[0m2.837    \u001b[0m | \u001b[0m0.4069   \u001b[0m | \u001b[0m0.1136   \u001b[0m | \u001b[0m47.73    \u001b[0m | \u001b[0m0.09509  \u001b[0m | \u001b[0m82.59    \u001b[0m | \u001b[0m0.4813   \u001b[0m | \u001b[0m6.767    \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.1322   \u001b[0m | \u001b[95m2.919    \u001b[0m | \u001b[95m51.71    \u001b[0m | \u001b[95m33.58    \u001b[0m | \u001b[95m3.076    \u001b[0m | \u001b[95m1.159    \u001b[0m | \u001b[95m1.256    \u001b[0m | \u001b[95m0.01669  \u001b[0m | \u001b[95m0.1906   \u001b[0m | \u001b[95m31.76    \u001b[0m | \u001b[95m0.01868  \u001b[0m | \u001b[95m26.14    \u001b[0m | \u001b[95m0.1496   \u001b[0m | \u001b[95m4.781    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.02925  \u001b[0m | \u001b[0m17.4     \u001b[0m | \u001b[0m75.67    \u001b[0m | \u001b[0m4.225    \u001b[0m | \u001b[0m3.055    \u001b[0m | \u001b[0m2.597    \u001b[0m | \u001b[0m0.1046   \u001b[0m | \u001b[0m0.3188   \u001b[0m | \u001b[0m49.37    \u001b[0m | \u001b[0m0.08119  \u001b[0m | \u001b[0m66.18    \u001b[0m | \u001b[0m0.8574   \u001b[0m | \u001b[0m6.044    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.972    \u001b[0m | \u001b[0m39.63    \u001b[0m | \u001b[0m69.42    \u001b[0m | \u001b[0m3.005    \u001b[0m | \u001b[0m1.346    \u001b[0m | \u001b[0m2.261    \u001b[0m | \u001b[0m0.3052   \u001b[0m | \u001b[0m0.3858   \u001b[0m | \u001b[0m12.24    \u001b[0m | \u001b[0m0.09091  \u001b[0m | \u001b[0m48.46    \u001b[0m | \u001b[0m0.06944  \u001b[0m | \u001b[0m2.493    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.757    \u001b[0m | \u001b[0m40.02    \u001b[0m | \u001b[0m111.9    \u001b[0m | \u001b[0m4.082    \u001b[0m | \u001b[0m1.429    \u001b[0m | \u001b[0m1.752    \u001b[0m | \u001b[0m0.1635   \u001b[0m | \u001b[0m0.15     \u001b[0m | \u001b[0m33.32    \u001b[0m | \u001b[0m0.03995  \u001b[0m | \u001b[0m69.25    \u001b[0m | \u001b[0m0.1085   \u001b[0m | \u001b[0m2.068    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.969    \u001b[0m | \u001b[0m50.3     \u001b[0m | \u001b[0m82.73    \u001b[0m | \u001b[0m4.941    \u001b[0m | \u001b[0m2.281    \u001b[0m | \u001b[0m2.032    \u001b[0m | \u001b[0m0.2519   \u001b[0m | \u001b[0m0.2394   \u001b[0m | \u001b[0m48.84    \u001b[0m | \u001b[0m0.06273  \u001b[0m | \u001b[0m22.87    \u001b[0m | \u001b[0m0.2632   \u001b[0m | \u001b[0m5.801    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.873    \u001b[0m | \u001b[0m17.95    \u001b[0m | \u001b[0m37.25    \u001b[0m | \u001b[0m4.033    \u001b[0m | \u001b[0m2.081    \u001b[0m | \u001b[0m2.657    \u001b[0m | \u001b[0m0.3751   \u001b[0m | \u001b[0m0.1485   \u001b[0m | \u001b[0m21.78    \u001b[0m | \u001b[0m0.04706  \u001b[0m | \u001b[0m73.77    \u001b[0m | \u001b[0m0.7389   \u001b[0m | \u001b[0m5.865    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.06749  \u001b[0m | \u001b[0m16.34    \u001b[0m | \u001b[0m112.8    \u001b[0m | \u001b[0m3.134    \u001b[0m | \u001b[0m3.466    \u001b[0m | \u001b[0m2.463    \u001b[0m | \u001b[0m0.3495   \u001b[0m | \u001b[0m0.328    \u001b[0m | \u001b[0m20.3     \u001b[0m | \u001b[0m0.04422  \u001b[0m | \u001b[0m14.61    \u001b[0m | \u001b[0m0.5586   \u001b[0m | \u001b[0m3.25     \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m5.58     \u001b[0m | \u001b[0m17.87    \u001b[0m | \u001b[0m55.77    \u001b[0m | \u001b[0m4.488    \u001b[0m | \u001b[0m1.722    \u001b[0m | \u001b[0m1.689    \u001b[0m | \u001b[0m0.3177   \u001b[0m | \u001b[0m0.4621   \u001b[0m | \u001b[0m16.52    \u001b[0m | \u001b[0m0.09883  \u001b[0m | \u001b[0m10.38    \u001b[0m | \u001b[0m0.1977   \u001b[0m | \u001b[0m2.192    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.363    \u001b[0m | \u001b[0m68.66    \u001b[0m | \u001b[0m123.7    \u001b[0m | \u001b[0m4.107    \u001b[0m | \u001b[0m3.612    \u001b[0m | \u001b[0m1.232    \u001b[0m | \u001b[0m0.01824  \u001b[0m | \u001b[0m0.3308   \u001b[0m | \u001b[0m10.83    \u001b[0m | \u001b[0m0.07249  \u001b[0m | \u001b[0m16.89    \u001b[0m | \u001b[0m0.8234   \u001b[0m | \u001b[0m6.073    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.985    \u001b[0m | \u001b[0m81.18    \u001b[0m | \u001b[0m66.32    \u001b[0m | \u001b[0m3.62     \u001b[0m | \u001b[0m3.197    \u001b[0m | \u001b[0m2.195    \u001b[0m | \u001b[0m0.4599   \u001b[0m | \u001b[0m0.2782   \u001b[0m | \u001b[0m10.07    \u001b[0m | \u001b[0m0.09443  \u001b[0m | \u001b[0m10.25    \u001b[0m | \u001b[0m0.8088   \u001b[0m | \u001b[0m6.885    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.08328  \u001b[0m | \u001b[0m108.9    \u001b[0m | \u001b[0m116.9    \u001b[0m | \u001b[0m3.645    \u001b[0m | \u001b[0m3.002    \u001b[0m | \u001b[0m2.488    \u001b[0m | \u001b[0m0.4357   \u001b[0m | \u001b[0m0.3143   \u001b[0m | \u001b[0m44.93    \u001b[0m | \u001b[0m0.0977   \u001b[0m | \u001b[0m11.19    \u001b[0m | \u001b[0m0.4239   \u001b[0m | \u001b[0m5.012    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.1318   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m16.0     \u001b[0m | \u001b[0m107.3    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m1.144    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m0.03434  \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m0.001    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.0      \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.1249   \u001b[0m | \u001b[0m5.292    \u001b[0m | \u001b[0m126.1    \u001b[0m | \u001b[0m122.6    \u001b[0m | \u001b[0m4.557    \u001b[0m | \u001b[0m1.023    \u001b[0m | \u001b[0m2.921    \u001b[0m | \u001b[0m0.1473   \u001b[0m | \u001b[0m0.2489   \u001b[0m | \u001b[0m10.28    \u001b[0m | \u001b[0m0.07209  \u001b[0m | \u001b[0m41.45    \u001b[0m | \u001b[0m0.08629  \u001b[0m | \u001b[0m3.317    \u001b[0m |\n",
      "WARNING:tensorflow:5 out of the last 68 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce1996b9fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 68 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce1996b9fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m18       \u001b[0m | \u001b[95m0.1369   \u001b[0m | \u001b[95m7.0      \u001b[0m | \u001b[95m48.19    \u001b[0m | \u001b[95m128.0    \u001b[0m | \u001b[95m4.621    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.5      \u001b[0m | \u001b[95m0.3947   \u001b[0m | \u001b[95m50.0     \u001b[0m | \u001b[95m0.001    \u001b[0m | \u001b[95m27.21    \u001b[0m | \u001b[95m0.2302   \u001b[0m | \u001b[95m1.411    \u001b[0m |\n",
      "| \u001b[95m19       \u001b[0m | \u001b[95m0.1457   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m71.84    \u001b[0m | \u001b[95m128.0    \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m4.0      \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.5      \u001b[0m | \u001b[95m50.0     \u001b[0m | \u001b[95m0.05362  \u001b[0m | \u001b[95m45.75    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m7.0      \u001b[0m |\n",
      "| \u001b[95m20       \u001b[0m | \u001b[95m0.1466   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m80.22    \u001b[0m | \u001b[95m128.0    \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m4.0      \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m0.5      \u001b[0m | \u001b[95m0.5      \u001b[0m | \u001b[95m50.0     \u001b[0m | \u001b[95m0.001    \u001b[0m | \u001b[95m62.46    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m83.27    \u001b[0m | \u001b[0m112.4    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m51.89    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m5.484    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.61     \u001b[0m | \u001b[0m48.16    \u001b[0m | \u001b[0m35.41    \u001b[0m | \u001b[0m3.337    \u001b[0m | \u001b[0m3.054    \u001b[0m | \u001b[0m2.039    \u001b[0m | \u001b[0m0.4497   \u001b[0m | \u001b[0m0.1051   \u001b[0m | \u001b[0m36.51    \u001b[0m | \u001b[0m0.04057  \u001b[0m | \u001b[0m23.44    \u001b[0m | \u001b[0m0.793    \u001b[0m | \u001b[0m6.531    \u001b[0m |\n",
      "| \u001b[95m23       \u001b[0m | \u001b[95m0.1539   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m62.43    \u001b[0m | \u001b[95m128.0    \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m4.0      \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.1      \u001b[0m | \u001b[95m50.0     \u001b[0m | \u001b[95m0.001    \u001b[0m | \u001b[95m61.1     \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[95m24       \u001b[0m | \u001b[95m0.1541   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m63.06    \u001b[0m | \u001b[95m128.0    \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m4.0      \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.1      \u001b[0m | \u001b[95m50.0     \u001b[0m | \u001b[95m0.001    \u001b[0m | \u001b[95m79.32    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.3037   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.1496   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m65.01    \u001b[0m | \u001b[0m128.0    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m39.97    \u001b[0m | \u001b[0m0.001    \u001b[0m | \u001b[0m71.55    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m7.0      \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m5.941    \u001b[0m | \u001b[0m62.6     \u001b[0m | \u001b[0m127.3    \u001b[0m | \u001b[0m4.942    \u001b[0m | \u001b[0m2.105    \u001b[0m | \u001b[0m2.548    \u001b[0m | \u001b[0m0.2514   \u001b[0m | \u001b[0m0.4135   \u001b[0m | \u001b[0m48.48    \u001b[0m | \u001b[0m0.03437  \u001b[0m | \u001b[0m74.89    \u001b[0m | \u001b[0m0.1647   \u001b[0m | \u001b[0m4.406    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.149    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m68.85    \u001b[0m | \u001b[0m128.0    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m44.03    \u001b[0m | \u001b[0m0.001    \u001b[0m | \u001b[0m64.2     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.1764   \u001b[0m | \u001b[0m60.96    \u001b[0m | \u001b[0m127.6    \u001b[0m | \u001b[0m4.461    \u001b[0m | \u001b[0m2.154    \u001b[0m | \u001b[0m2.216    \u001b[0m | \u001b[0m0.1648   \u001b[0m | \u001b[0m0.136    \u001b[0m | \u001b[0m39.76    \u001b[0m | \u001b[0m0.0964   \u001b[0m | \u001b[0m60.38    \u001b[0m | \u001b[0m0.2764   \u001b[0m | \u001b[0m1.372    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.237    \u001b[0m | \u001b[0m68.03    \u001b[0m | \u001b[0m126.6    \u001b[0m | \u001b[0m4.573    \u001b[0m | \u001b[0m2.48     \u001b[0m | \u001b[0m2.217    \u001b[0m | \u001b[0m0.159    \u001b[0m | \u001b[0m0.1811   \u001b[0m | \u001b[0m48.79    \u001b[0m | \u001b[0m0.04776  \u001b[0m | \u001b[0m55.47    \u001b[0m | \u001b[0m0.2934   \u001b[0m | \u001b[0m2.151    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.189    \u001b[0m | \u001b[0m77.65    \u001b[0m | \u001b[0m127.8    \u001b[0m | \u001b[0m4.16     \u001b[0m | \u001b[0m3.032    \u001b[0m | \u001b[0m2.619    \u001b[0m | \u001b[0m0.1072   \u001b[0m | \u001b[0m0.1337   \u001b[0m | \u001b[0m45.39    \u001b[0m | \u001b[0m0.09729  \u001b[0m | \u001b[0m65.87    \u001b[0m | \u001b[0m0.2866   \u001b[0m | \u001b[0m0.1099   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.6155   \u001b[0m | \u001b[0m60.63    \u001b[0m | \u001b[0m123.0    \u001b[0m | \u001b[0m3.288    \u001b[0m | \u001b[0m3.728    \u001b[0m | \u001b[0m1.9      \u001b[0m | \u001b[0m0.4447   \u001b[0m | \u001b[0m0.1346   \u001b[0m | \u001b[0m49.98    \u001b[0m | \u001b[0m0.05392  \u001b[0m | \u001b[0m66.64    \u001b[0m | \u001b[0m0.9841   \u001b[0m | \u001b[0m2.177    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.105    \u001b[0m | \u001b[0m68.84    \u001b[0m | \u001b[0m126.1    \u001b[0m | \u001b[0m3.994    \u001b[0m | \u001b[0m2.148    \u001b[0m | \u001b[0m2.285    \u001b[0m | \u001b[0m0.3949   \u001b[0m | \u001b[0m0.2055   \u001b[0m | \u001b[0m43.53    \u001b[0m | \u001b[0m0.009183 \u001b[0m | \u001b[0m61.38    \u001b[0m | \u001b[0m0.9745   \u001b[0m | \u001b[0m3.366    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.374    \u001b[0m | \u001b[0m65.97    \u001b[0m | \u001b[0m126.4    \u001b[0m | \u001b[0m4.49     \u001b[0m | \u001b[0m2.275    \u001b[0m | \u001b[0m1.149    \u001b[0m | \u001b[0m0.08467  \u001b[0m | \u001b[0m0.1223   \u001b[0m | \u001b[0m32.87    \u001b[0m | \u001b[0m0.0803   \u001b[0m | \u001b[0m70.96    \u001b[0m | \u001b[0m0.1475   \u001b[0m | \u001b[0m4.782    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.721    \u001b[0m | \u001b[0m65.24    \u001b[0m | \u001b[0m127.1    \u001b[0m | \u001b[0m3.761    \u001b[0m | \u001b[0m2.041    \u001b[0m | \u001b[0m2.228    \u001b[0m | \u001b[0m0.1815   \u001b[0m | \u001b[0m0.3376   \u001b[0m | \u001b[0m41.98    \u001b[0m | \u001b[0m0.04485  \u001b[0m | \u001b[0m84.75    \u001b[0m | \u001b[0m0.9942   \u001b[0m | \u001b[0m1.281    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.642    \u001b[0m | \u001b[0m61.42    \u001b[0m | \u001b[0m127.2    \u001b[0m | \u001b[0m4.847    \u001b[0m | \u001b[0m2.963    \u001b[0m | \u001b[0m1.964    \u001b[0m | \u001b[0m0.1425   \u001b[0m | \u001b[0m0.1648   \u001b[0m | \u001b[0m49.71    \u001b[0m | \u001b[0m0.03808  \u001b[0m | \u001b[0m79.94    \u001b[0m | \u001b[0m0.1485   \u001b[0m | \u001b[0m1.602    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m5.964    \u001b[0m | \u001b[0m23.54    \u001b[0m | \u001b[0m93.89    \u001b[0m | \u001b[0m3.933    \u001b[0m | \u001b[0m3.905    \u001b[0m | \u001b[0m2.449    \u001b[0m | \u001b[0m0.168    \u001b[0m | \u001b[0m0.2505   \u001b[0m | \u001b[0m25.02    \u001b[0m | \u001b[0m0.07558  \u001b[0m | \u001b[0m34.16    \u001b[0m | \u001b[0m0.7695   \u001b[0m | \u001b[0m5.722    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.145    \u001b[0m | \u001b[0m33.63    \u001b[0m | \u001b[0m44.61    \u001b[0m | \u001b[0m4.757    \u001b[0m | \u001b[0m1.543    \u001b[0m | \u001b[0m1.126    \u001b[0m | \u001b[0m0.2615   \u001b[0m | \u001b[0m0.4161   \u001b[0m | \u001b[0m27.02    \u001b[0m | \u001b[0m0.02106  \u001b[0m | \u001b[0m95.54    \u001b[0m | \u001b[0m0.04329  \u001b[0m | \u001b[0m4.626    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.758    \u001b[0m | \u001b[0m18.83    \u001b[0m | \u001b[0m119.6    \u001b[0m | \u001b[0m3.424    \u001b[0m | \u001b[0m1.52     \u001b[0m | \u001b[0m2.916    \u001b[0m | \u001b[0m0.4007   \u001b[0m | \u001b[0m0.1361   \u001b[0m | \u001b[0m23.2     \u001b[0m | \u001b[0m0.04161  \u001b[0m | \u001b[0m51.84    \u001b[0m | \u001b[0m0.7772   \u001b[0m | \u001b[0m5.621    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.29     \u001b[0m | \u001b[0m20.73    \u001b[0m | \u001b[0m45.01    \u001b[0m | \u001b[0m3.575    \u001b[0m | \u001b[0m3.884    \u001b[0m | \u001b[0m1.463    \u001b[0m | \u001b[0m0.02166  \u001b[0m | \u001b[0m0.436    \u001b[0m | \u001b[0m13.41    \u001b[0m | \u001b[0m0.09908  \u001b[0m | \u001b[0m46.32    \u001b[0m | \u001b[0m0.2638   \u001b[0m | \u001b[0m1.555    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m5.899    \u001b[0m | \u001b[0m20.17    \u001b[0m | \u001b[0m114.1    \u001b[0m | \u001b[0m3.745    \u001b[0m | \u001b[0m2.826    \u001b[0m | \u001b[0m2.376    \u001b[0m | \u001b[0m0.4131   \u001b[0m | \u001b[0m0.4235   \u001b[0m | \u001b[0m36.8     \u001b[0m | \u001b[0m0.05422  \u001b[0m | \u001b[0m50.99    \u001b[0m | \u001b[0m0.2218   \u001b[0m | \u001b[0m2.36     \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.387    \u001b[0m | \u001b[0m23.6     \u001b[0m | \u001b[0m118.9    \u001b[0m | \u001b[0m3.415    \u001b[0m | \u001b[0m3.019    \u001b[0m | \u001b[0m1.612    \u001b[0m | \u001b[0m0.3391   \u001b[0m | \u001b[0m0.3625   \u001b[0m | \u001b[0m31.44    \u001b[0m | \u001b[0m0.084    \u001b[0m | \u001b[0m89.97    \u001b[0m | \u001b[0m0.05792  \u001b[0m | \u001b[0m1.875    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.134    \u001b[0m | \u001b[0m84.46    \u001b[0m | \u001b[0m114.2    \u001b[0m | \u001b[0m4.65     \u001b[0m | \u001b[0m1.578    \u001b[0m | \u001b[0m1.044    \u001b[0m | \u001b[0m0.02136  \u001b[0m | \u001b[0m0.4489   \u001b[0m | \u001b[0m17.16    \u001b[0m | \u001b[0m0.06115  \u001b[0m | \u001b[0m26.02    \u001b[0m | \u001b[0m0.9864   \u001b[0m | \u001b[0m5.86     \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.1307   \u001b[0m | \u001b[0m5.655    \u001b[0m | \u001b[0m79.04    \u001b[0m | \u001b[0m116.8    \u001b[0m | \u001b[0m3.61     \u001b[0m | \u001b[0m3.602    \u001b[0m | \u001b[0m2.578    \u001b[0m | \u001b[0m0.3859   \u001b[0m | \u001b[0m0.4594   \u001b[0m | \u001b[0m10.4     \u001b[0m | \u001b[0m0.068    \u001b[0m | \u001b[0m65.95    \u001b[0m | \u001b[0m0.6427   \u001b[0m | \u001b[0m1.757    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.866    \u001b[0m | \u001b[0m68.79    \u001b[0m | \u001b[0m56.79    \u001b[0m | \u001b[0m3.147    \u001b[0m | \u001b[0m1.693    \u001b[0m | \u001b[0m2.424    \u001b[0m | \u001b[0m0.4596   \u001b[0m | \u001b[0m0.3884   \u001b[0m | \u001b[0m15.39    \u001b[0m | \u001b[0m0.03794  \u001b[0m | \u001b[0m97.85    \u001b[0m | \u001b[0m0.8412   \u001b[0m | \u001b[0m5.27     \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.106    \u001b[0m | \u001b[0m92.93    \u001b[0m | \u001b[0m79.64    \u001b[0m | \u001b[0m4.252    \u001b[0m | \u001b[0m1.649    \u001b[0m | \u001b[0m1.212    \u001b[0m | \u001b[0m0.04534  \u001b[0m | \u001b[0m0.274    \u001b[0m | \u001b[0m15.55    \u001b[0m | \u001b[0m0.08087  \u001b[0m | \u001b[0m95.37    \u001b[0m | \u001b[0m0.4283   \u001b[0m | \u001b[0m3.394    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.979    \u001b[0m | \u001b[0m19.53    \u001b[0m | \u001b[0m32.47    \u001b[0m | \u001b[0m3.682    \u001b[0m | \u001b[0m1.544    \u001b[0m | \u001b[0m1.724    \u001b[0m | \u001b[0m0.4542   \u001b[0m | \u001b[0m0.4967   \u001b[0m | \u001b[0m47.0     \u001b[0m | \u001b[0m0.06346  \u001b[0m | \u001b[0m35.57    \u001b[0m | \u001b[0m0.9884   \u001b[0m | \u001b[0m2.109    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.695    \u001b[0m | \u001b[0m68.65    \u001b[0m | \u001b[0m123.2    \u001b[0m | \u001b[0m3.737    \u001b[0m | \u001b[0m1.238    \u001b[0m | \u001b[0m1.393    \u001b[0m | \u001b[0m0.07753  \u001b[0m | \u001b[0m0.3254   \u001b[0m | \u001b[0m33.39    \u001b[0m | \u001b[0m0.01855  \u001b[0m | \u001b[0m51.35    \u001b[0m | \u001b[0m0.6092   \u001b[0m | \u001b[0m0.7453   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.2317   \u001b[0m | \u001b[0m65.32    \u001b[0m | \u001b[0m113.3    \u001b[0m | \u001b[0m4.561    \u001b[0m | \u001b[0m1.713    \u001b[0m | \u001b[0m2.602    \u001b[0m | \u001b[0m0.1739   \u001b[0m | \u001b[0m0.1462   \u001b[0m | \u001b[0m41.46    \u001b[0m | \u001b[0m0.06235  \u001b[0m | \u001b[0m56.92    \u001b[0m | \u001b[0m0.9693   \u001b[0m | \u001b[0m2.875    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.482    \u001b[0m | \u001b[0m49.35    \u001b[0m | \u001b[0m40.13    \u001b[0m | \u001b[0m3.865    \u001b[0m | \u001b[0m3.882    \u001b[0m | \u001b[0m1.251    \u001b[0m | \u001b[0m0.2371   \u001b[0m | \u001b[0m0.4992   \u001b[0m | \u001b[0m45.91    \u001b[0m | \u001b[0m0.06026  \u001b[0m | \u001b[0m10.24    \u001b[0m | \u001b[0m0.7681   \u001b[0m | \u001b[0m5.992    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.1457   \u001b[0m | \u001b[0m2.465    \u001b[0m | \u001b[0m110.4    \u001b[0m | \u001b[0m33.97    \u001b[0m | \u001b[0m3.001    \u001b[0m | \u001b[0m3.086    \u001b[0m | \u001b[0m2.537    \u001b[0m | \u001b[0m0.2962   \u001b[0m | \u001b[0m0.4438   \u001b[0m | \u001b[0m47.03    \u001b[0m | \u001b[0m0.002452 \u001b[0m | \u001b[0m69.51    \u001b[0m | \u001b[0m0.9267   \u001b[0m | \u001b[0m0.9064   \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.015    \u001b[0m | \u001b[0m98.51    \u001b[0m | \u001b[0m37.17    \u001b[0m | \u001b[0m4.883    \u001b[0m | \u001b[0m2.01     \u001b[0m | \u001b[0m2.914    \u001b[0m | \u001b[0m0.3794   \u001b[0m | \u001b[0m0.1969   \u001b[0m | \u001b[0m12.12    \u001b[0m | \u001b[0m0.02421  \u001b[0m | \u001b[0m72.04    \u001b[0m | \u001b[0m0.1259   \u001b[0m | \u001b[0m1.511    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m5.642    \u001b[0m | \u001b[0m67.25    \u001b[0m | \u001b[0m110.3    \u001b[0m | \u001b[0m3.222    \u001b[0m | \u001b[0m3.34     \u001b[0m | \u001b[0m1.619    \u001b[0m | \u001b[0m0.4192   \u001b[0m | \u001b[0m0.1798   \u001b[0m | \u001b[0m43.09    \u001b[0m | \u001b[0m0.09602  \u001b[0m | \u001b[0m77.05    \u001b[0m | \u001b[0m0.4283   \u001b[0m | \u001b[0m6.679    \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.8433   \u001b[0m | \u001b[0m45.89    \u001b[0m | \u001b[0m48.96    \u001b[0m | \u001b[0m3.084    \u001b[0m | \u001b[0m3.871    \u001b[0m | \u001b[0m1.593    \u001b[0m | \u001b[0m0.337    \u001b[0m | \u001b[0m0.4352   \u001b[0m | \u001b[0m37.22    \u001b[0m | \u001b[0m0.02827  \u001b[0m | \u001b[0m27.21    \u001b[0m | \u001b[0m0.8959   \u001b[0m | \u001b[0m5.941    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.352    \u001b[0m | \u001b[0m76.43    \u001b[0m | \u001b[0m126.2    \u001b[0m | \u001b[0m3.317    \u001b[0m | \u001b[0m1.378    \u001b[0m | \u001b[0m1.758    \u001b[0m | \u001b[0m0.06919  \u001b[0m | \u001b[0m0.3698   \u001b[0m | \u001b[0m47.74    \u001b[0m | \u001b[0m0.07421  \u001b[0m | \u001b[0m47.28    \u001b[0m | \u001b[0m0.02953  \u001b[0m | \u001b[0m2.966    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.245    \u001b[0m | \u001b[0m63.49    \u001b[0m | \u001b[0m81.13    \u001b[0m | \u001b[0m3.485    \u001b[0m | \u001b[0m2.796    \u001b[0m | \u001b[0m2.518    \u001b[0m | \u001b[0m0.04966  \u001b[0m | \u001b[0m0.2891   \u001b[0m | \u001b[0m10.79    \u001b[0m | \u001b[0m0.0374   \u001b[0m | \u001b[0m30.62    \u001b[0m | \u001b[0m0.1615   \u001b[0m | \u001b[0m1.344    \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.048    \u001b[0m | \u001b[0m102.2    \u001b[0m | \u001b[0m115.9    \u001b[0m | \u001b[0m4.703    \u001b[0m | \u001b[0m1.285    \u001b[0m | \u001b[0m2.854    \u001b[0m | \u001b[0m0.4311   \u001b[0m | \u001b[0m0.2081   \u001b[0m | \u001b[0m22.03    \u001b[0m | \u001b[0m0.08271  \u001b[0m | \u001b[0m47.42    \u001b[0m | \u001b[0m0.7242   \u001b[0m | \u001b[0m4.662    \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.1367   \u001b[0m | \u001b[0m2.491    \u001b[0m | \u001b[0m41.36    \u001b[0m | \u001b[0m66.21    \u001b[0m | \u001b[0m3.151    \u001b[0m | \u001b[0m1.62     \u001b[0m | \u001b[0m2.546    \u001b[0m | \u001b[0m0.2475   \u001b[0m | \u001b[0m0.1717   \u001b[0m | \u001b[0m48.49    \u001b[0m | \u001b[0m0.009736 \u001b[0m | \u001b[0m63.2     \u001b[0m | \u001b[0m0.9569   \u001b[0m | \u001b[0m1.824    \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.1219   \u001b[0m | \u001b[0m4.547    \u001b[0m | \u001b[0m27.32    \u001b[0m | \u001b[0m41.23    \u001b[0m | \u001b[0m3.602    \u001b[0m | \u001b[0m1.324    \u001b[0m | \u001b[0m1.129    \u001b[0m | \u001b[0m0.3412   \u001b[0m | \u001b[0m0.1818   \u001b[0m | \u001b[0m42.58    \u001b[0m | \u001b[0m0.03141  \u001b[0m | \u001b[0m82.21    \u001b[0m | \u001b[0m0.2179   \u001b[0m | \u001b[0m0.5923   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.1328   \u001b[0m | \u001b[0m6.36     \u001b[0m | \u001b[0m107.5    \u001b[0m | \u001b[0m124.4    \u001b[0m | \u001b[0m3.296    \u001b[0m | \u001b[0m1.178    \u001b[0m | \u001b[0m1.557    \u001b[0m | \u001b[0m0.3331   \u001b[0m | \u001b[0m0.4924   \u001b[0m | \u001b[0m38.78    \u001b[0m | \u001b[0m0.02502  \u001b[0m | \u001b[0m11.04    \u001b[0m | \u001b[0m0.429    \u001b[0m | \u001b[0m1.201    \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.752    \u001b[0m | \u001b[0m108.5    \u001b[0m | \u001b[0m97.63    \u001b[0m | \u001b[0m3.184    \u001b[0m | \u001b[0m1.875    \u001b[0m | \u001b[0m1.374    \u001b[0m | \u001b[0m0.2021   \u001b[0m | \u001b[0m0.3607   \u001b[0m | \u001b[0m32.6     \u001b[0m | \u001b[0m0.07743  \u001b[0m | \u001b[0m35.69    \u001b[0m | \u001b[0m0.3305   \u001b[0m | \u001b[0m4.31     \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.585    \u001b[0m | \u001b[0m90.75    \u001b[0m | \u001b[0m105.8    \u001b[0m | \u001b[0m4.763    \u001b[0m | \u001b[0m2.785    \u001b[0m | \u001b[0m2.683    \u001b[0m | \u001b[0m0.4508   \u001b[0m | \u001b[0m0.1504   \u001b[0m | \u001b[0m40.05    \u001b[0m | \u001b[0m0.03657  \u001b[0m | \u001b[0m53.72    \u001b[0m | \u001b[0m0.9593   \u001b[0m | \u001b[0m3.328    \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.211    \u001b[0m | \u001b[0m109.4    \u001b[0m | \u001b[0m73.26    \u001b[0m | \u001b[0m4.24     \u001b[0m | \u001b[0m1.735    \u001b[0m | \u001b[0m1.56     \u001b[0m | \u001b[0m0.426    \u001b[0m | \u001b[0m0.1429   \u001b[0m | \u001b[0m34.76    \u001b[0m | \u001b[0m0.09462  \u001b[0m | \u001b[0m38.73    \u001b[0m | \u001b[0m0.9011   \u001b[0m | \u001b[0m3.024    \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.054    \u001b[0m | \u001b[0m21.82    \u001b[0m | \u001b[0m74.15    \u001b[0m | \u001b[0m4.254    \u001b[0m | \u001b[0m3.484    \u001b[0m | \u001b[0m2.304    \u001b[0m | \u001b[0m0.04412  \u001b[0m | \u001b[0m0.326    \u001b[0m | \u001b[0m21.76    \u001b[0m | \u001b[0m0.07254  \u001b[0m | \u001b[0m13.27    \u001b[0m | \u001b[0m0.4204   \u001b[0m | \u001b[0m3.946    \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.619    \u001b[0m | \u001b[0m85.48    \u001b[0m | \u001b[0m54.0     \u001b[0m | \u001b[0m3.313    \u001b[0m | \u001b[0m2.192    \u001b[0m | \u001b[0m1.542    \u001b[0m | \u001b[0m0.3573   \u001b[0m | \u001b[0m0.3201   \u001b[0m | \u001b[0m15.8     \u001b[0m | \u001b[0m0.05859  \u001b[0m | \u001b[0m65.12    \u001b[0m | \u001b[0m0.5858   \u001b[0m | \u001b[0m1.922    \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.951    \u001b[0m | \u001b[0m82.62    \u001b[0m | \u001b[0m114.3    \u001b[0m | \u001b[0m3.091    \u001b[0m | \u001b[0m2.139    \u001b[0m | \u001b[0m2.509    \u001b[0m | \u001b[0m0.3862   \u001b[0m | \u001b[0m0.4617   \u001b[0m | \u001b[0m24.42    \u001b[0m | \u001b[0m0.01337  \u001b[0m | \u001b[0m77.96    \u001b[0m | \u001b[0m0.3452   \u001b[0m | \u001b[0m3.689    \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m0.1466   \u001b[0m | \u001b[0m3.325    \u001b[0m | \u001b[0m127.6    \u001b[0m | \u001b[0m119.4    \u001b[0m | \u001b[0m4.966    \u001b[0m | \u001b[0m1.521    \u001b[0m | \u001b[0m2.321    \u001b[0m | \u001b[0m0.1587   \u001b[0m | \u001b[0m0.4098   \u001b[0m | \u001b[0m12.94    \u001b[0m | \u001b[0m0.00314  \u001b[0m | \u001b[0m34.76    \u001b[0m | \u001b[0m0.4806   \u001b[0m | \u001b[0m1.163    \u001b[0m |\n",
      "WARNING:tensorflow:5 out of the last 21 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce2126a2560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 21 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce2126a2560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m67       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.986    \u001b[0m | \u001b[0m23.44    \u001b[0m | \u001b[0m106.4    \u001b[0m | \u001b[0m4.799    \u001b[0m | \u001b[0m3.711    \u001b[0m | \u001b[0m1.252    \u001b[0m | \u001b[0m0.04829  \u001b[0m | \u001b[0m0.4682   \u001b[0m | \u001b[0m28.08    \u001b[0m | \u001b[0m0.06447  \u001b[0m | \u001b[0m29.05    \u001b[0m | \u001b[0m0.1311   \u001b[0m | \u001b[0m2.992    \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m5.953    \u001b[0m | \u001b[0m27.17    \u001b[0m | \u001b[0m58.22    \u001b[0m | \u001b[0m3.761    \u001b[0m | \u001b[0m1.864    \u001b[0m | \u001b[0m1.72     \u001b[0m | \u001b[0m0.005637 \u001b[0m | \u001b[0m0.4083   \u001b[0m | \u001b[0m44.68    \u001b[0m | \u001b[0m0.03107  \u001b[0m | \u001b[0m54.27    \u001b[0m | \u001b[0m0.6094   \u001b[0m | \u001b[0m0.3428   \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.841    \u001b[0m | \u001b[0m65.18    \u001b[0m | \u001b[0m102.9    \u001b[0m | \u001b[0m3.572    \u001b[0m | \u001b[0m1.275    \u001b[0m | \u001b[0m2.774    \u001b[0m | \u001b[0m0.2704   \u001b[0m | \u001b[0m0.2586   \u001b[0m | \u001b[0m48.73    \u001b[0m | \u001b[0m0.02801  \u001b[0m | \u001b[0m56.57    \u001b[0m | \u001b[0m0.7781   \u001b[0m | \u001b[0m2.748    \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.539    \u001b[0m | \u001b[0m80.41    \u001b[0m | \u001b[0m111.9    \u001b[0m | \u001b[0m3.898    \u001b[0m | \u001b[0m3.749    \u001b[0m | \u001b[0m1.515    \u001b[0m | \u001b[0m0.4632   \u001b[0m | \u001b[0m0.4537   \u001b[0m | \u001b[0m42.01    \u001b[0m | \u001b[0m0.0314   \u001b[0m | \u001b[0m67.71    \u001b[0m | \u001b[0m0.847    \u001b[0m | \u001b[0m2.298    \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.228    \u001b[0m | \u001b[0m114.7    \u001b[0m | \u001b[0m99.73    \u001b[0m | \u001b[0m4.891    \u001b[0m | \u001b[0m2.62     \u001b[0m | \u001b[0m2.664    \u001b[0m | \u001b[0m0.3855   \u001b[0m | \u001b[0m0.4503   \u001b[0m | \u001b[0m20.99    \u001b[0m | \u001b[0m0.07016  \u001b[0m | \u001b[0m55.28    \u001b[0m | \u001b[0m0.3847   \u001b[0m | \u001b[0m5.244    \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.013    \u001b[0m | \u001b[0m49.03    \u001b[0m | \u001b[0m79.7     \u001b[0m | \u001b[0m3.299    \u001b[0m | \u001b[0m2.84     \u001b[0m | \u001b[0m2.451    \u001b[0m | \u001b[0m0.04304  \u001b[0m | \u001b[0m0.4297   \u001b[0m | \u001b[0m46.94    \u001b[0m | \u001b[0m0.09674  \u001b[0m | \u001b[0m89.93    \u001b[0m | \u001b[0m0.04804  \u001b[0m | \u001b[0m3.044    \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.331    \u001b[0m | \u001b[0m63.55    \u001b[0m | \u001b[0m103.3    \u001b[0m | \u001b[0m3.013    \u001b[0m | \u001b[0m3.029    \u001b[0m | \u001b[0m2.593    \u001b[0m | \u001b[0m0.2025   \u001b[0m | \u001b[0m0.4621   \u001b[0m | \u001b[0m26.11    \u001b[0m | \u001b[0m0.04978  \u001b[0m | \u001b[0m12.95    \u001b[0m | \u001b[0m0.1592   \u001b[0m | \u001b[0m5.011    \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.72     \u001b[0m | \u001b[0m95.76    \u001b[0m | \u001b[0m115.4    \u001b[0m | \u001b[0m4.547    \u001b[0m | \u001b[0m2.53     \u001b[0m | \u001b[0m2.676    \u001b[0m | \u001b[0m0.478    \u001b[0m | \u001b[0m0.1678   \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m0.03339  \u001b[0m | \u001b[0m96.77    \u001b[0m | \u001b[0m0.5648   \u001b[0m | \u001b[0m5.091    \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.5523   \u001b[0m | \u001b[0m43.59    \u001b[0m | \u001b[0m78.55    \u001b[0m | \u001b[0m3.844    \u001b[0m | \u001b[0m3.897    \u001b[0m | \u001b[0m2.271    \u001b[0m | \u001b[0m0.3397   \u001b[0m | \u001b[0m0.418    \u001b[0m | \u001b[0m24.49    \u001b[0m | \u001b[0m0.07673  \u001b[0m | \u001b[0m42.67    \u001b[0m | \u001b[0m0.07931  \u001b[0m | \u001b[0m0.1105   \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m0.147    \u001b[0m | \u001b[0m3.573    \u001b[0m | \u001b[0m88.02    \u001b[0m | \u001b[0m44.98    \u001b[0m | \u001b[0m4.939    \u001b[0m | \u001b[0m3.298    \u001b[0m | \u001b[0m1.912    \u001b[0m | \u001b[0m0.1497   \u001b[0m | \u001b[0m0.2524   \u001b[0m | \u001b[0m36.9     \u001b[0m | \u001b[0m0.006716 \u001b[0m | \u001b[0m67.67    \u001b[0m | \u001b[0m0.07391  \u001b[0m | \u001b[0m4.625    \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.896    \u001b[0m | \u001b[0m71.35    \u001b[0m | \u001b[0m76.92    \u001b[0m | \u001b[0m3.989    \u001b[0m | \u001b[0m2.951    \u001b[0m | \u001b[0m1.219    \u001b[0m | \u001b[0m0.1729   \u001b[0m | \u001b[0m0.2988   \u001b[0m | \u001b[0m23.5     \u001b[0m | \u001b[0m0.02207  \u001b[0m | \u001b[0m58.08    \u001b[0m | \u001b[0m0.5333   \u001b[0m | \u001b[0m0.0659   \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.259    \u001b[0m | \u001b[0m100.4    \u001b[0m | \u001b[0m88.84    \u001b[0m | \u001b[0m4.772    \u001b[0m | \u001b[0m2.731    \u001b[0m | \u001b[0m1.525    \u001b[0m | \u001b[0m0.1785   \u001b[0m | \u001b[0m0.4899   \u001b[0m | \u001b[0m46.53    \u001b[0m | \u001b[0m0.06829  \u001b[0m | \u001b[0m15.97    \u001b[0m | \u001b[0m0.232    \u001b[0m | \u001b[0m2.831    \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.924    \u001b[0m | \u001b[0m52.38    \u001b[0m | \u001b[0m71.75    \u001b[0m | \u001b[0m4.548    \u001b[0m | \u001b[0m3.413    \u001b[0m | \u001b[0m1.511    \u001b[0m | \u001b[0m0.2508   \u001b[0m | \u001b[0m0.2932   \u001b[0m | \u001b[0m39.72    \u001b[0m | \u001b[0m0.09206  \u001b[0m | \u001b[0m76.89    \u001b[0m | \u001b[0m0.4544   \u001b[0m | \u001b[0m2.026    \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.105    \u001b[0m | \u001b[0m87.15    \u001b[0m | \u001b[0m107.8    \u001b[0m | \u001b[0m3.378    \u001b[0m | \u001b[0m1.483    \u001b[0m | \u001b[0m1.877    \u001b[0m | \u001b[0m0.4834   \u001b[0m | \u001b[0m0.4931   \u001b[0m | \u001b[0m22.66    \u001b[0m | \u001b[0m0.07117  \u001b[0m | \u001b[0m44.06    \u001b[0m | \u001b[0m0.1006   \u001b[0m | \u001b[0m2.552    \u001b[0m |\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.247    \u001b[0m | \u001b[0m49.12    \u001b[0m | \u001b[0m106.4    \u001b[0m | \u001b[0m4.461    \u001b[0m | \u001b[0m2.652    \u001b[0m | \u001b[0m1.352    \u001b[0m | \u001b[0m0.1662   \u001b[0m | \u001b[0m0.4537   \u001b[0m | \u001b[0m37.67    \u001b[0m | \u001b[0m0.07175  \u001b[0m | \u001b[0m34.84    \u001b[0m | \u001b[0m0.5639   \u001b[0m | \u001b[0m6.884    \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.959    \u001b[0m | \u001b[0m121.4    \u001b[0m | \u001b[0m39.37    \u001b[0m | \u001b[0m4.075    \u001b[0m | \u001b[0m2.95     \u001b[0m | \u001b[0m2.37     \u001b[0m | \u001b[0m0.1583   \u001b[0m | \u001b[0m0.4922   \u001b[0m | \u001b[0m14.64    \u001b[0m | \u001b[0m0.03437  \u001b[0m | \u001b[0m28.52    \u001b[0m | \u001b[0m0.2999   \u001b[0m | \u001b[0m2.659    \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.677    \u001b[0m | \u001b[0m23.29    \u001b[0m | \u001b[0m87.53    \u001b[0m | \u001b[0m3.665    \u001b[0m | \u001b[0m1.291    \u001b[0m | \u001b[0m2.256    \u001b[0m | \u001b[0m0.4944   \u001b[0m | \u001b[0m0.2363   \u001b[0m | \u001b[0m26.75    \u001b[0m | \u001b[0m0.03929  \u001b[0m | \u001b[0m85.34    \u001b[0m | \u001b[0m0.9531   \u001b[0m | \u001b[0m5.44     \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.09978  \u001b[0m | \u001b[0m93.37    \u001b[0m | \u001b[0m46.22    \u001b[0m | \u001b[0m3.093    \u001b[0m | \u001b[0m1.032    \u001b[0m | \u001b[0m1.837    \u001b[0m | \u001b[0m0.4862   \u001b[0m | \u001b[0m0.3335   \u001b[0m | \u001b[0m40.66    \u001b[0m | \u001b[0m0.07303  \u001b[0m | \u001b[0m78.89    \u001b[0m | \u001b[0m0.1402   \u001b[0m | \u001b[0m5.544    \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m5.735    \u001b[0m | \u001b[0m33.93    \u001b[0m | \u001b[0m113.3    \u001b[0m | \u001b[0m4.99     \u001b[0m | \u001b[0m1.96     \u001b[0m | \u001b[0m2.936    \u001b[0m | \u001b[0m0.2654   \u001b[0m | \u001b[0m0.2133   \u001b[0m | \u001b[0m36.73    \u001b[0m | \u001b[0m0.03757  \u001b[0m | \u001b[0m41.07    \u001b[0m | \u001b[0m0.4275   \u001b[0m | \u001b[0m0.4173   \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m0.1438   \u001b[0m | \u001b[0m4.24     \u001b[0m | \u001b[0m72.45    \u001b[0m | \u001b[0m41.59    \u001b[0m | \u001b[0m3.066    \u001b[0m | \u001b[0m3.362    \u001b[0m | \u001b[0m1.284    \u001b[0m | \u001b[0m0.3001   \u001b[0m | \u001b[0m0.4914   \u001b[0m | \u001b[0m21.79    \u001b[0m | \u001b[0m0.004013 \u001b[0m | \u001b[0m88.76    \u001b[0m | \u001b[0m0.4452   \u001b[0m | \u001b[0m3.177    \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.571    \u001b[0m | \u001b[0m127.6    \u001b[0m | \u001b[0m91.46    \u001b[0m | \u001b[0m3.391    \u001b[0m | \u001b[0m2.932    \u001b[0m | \u001b[0m1.746    \u001b[0m | \u001b[0m0.1151   \u001b[0m | \u001b[0m0.3018   \u001b[0m | \u001b[0m15.71    \u001b[0m | \u001b[0m0.07049  \u001b[0m | \u001b[0m46.06    \u001b[0m | \u001b[0m0.4463   \u001b[0m | \u001b[0m4.645    \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.791    \u001b[0m | \u001b[0m54.21    \u001b[0m | \u001b[0m117.3    \u001b[0m | \u001b[0m3.133    \u001b[0m | \u001b[0m1.279    \u001b[0m | \u001b[0m2.56     \u001b[0m | \u001b[0m0.1249   \u001b[0m | \u001b[0m0.2431   \u001b[0m | \u001b[0m25.62    \u001b[0m | \u001b[0m0.07522  \u001b[0m | \u001b[0m64.64    \u001b[0m | \u001b[0m0.6887   \u001b[0m | \u001b[0m4.787    \u001b[0m |\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.437    \u001b[0m | \u001b[0m105.6    \u001b[0m | \u001b[0m32.74    \u001b[0m | \u001b[0m3.739    \u001b[0m | \u001b[0m3.275    \u001b[0m | \u001b[0m2.109    \u001b[0m | \u001b[0m0.1829   \u001b[0m | \u001b[0m0.2412   \u001b[0m | \u001b[0m12.38    \u001b[0m | \u001b[0m0.05701  \u001b[0m | \u001b[0m77.9     \u001b[0m | \u001b[0m0.1173   \u001b[0m | \u001b[0m2.908    \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m0.6521   \u001b[0m | \u001b[0m126.6    \u001b[0m | \u001b[0m117.9    \u001b[0m | \u001b[0m3.211    \u001b[0m | \u001b[0m2.855    \u001b[0m | \u001b[0m2.297    \u001b[0m | \u001b[0m0.409    \u001b[0m | \u001b[0m0.2486   \u001b[0m | \u001b[0m41.77    \u001b[0m | \u001b[0m0.09869  \u001b[0m | \u001b[0m30.15    \u001b[0m | \u001b[0m0.8565   \u001b[0m | \u001b[0m2.663    \u001b[0m |\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.918    \u001b[0m | \u001b[0m25.27    \u001b[0m | \u001b[0m91.83    \u001b[0m | \u001b[0m4.731    \u001b[0m | \u001b[0m3.542    \u001b[0m | \u001b[0m1.345    \u001b[0m | \u001b[0m0.3399   \u001b[0m | \u001b[0m0.116    \u001b[0m | \u001b[0m14.35    \u001b[0m | \u001b[0m0.04554  \u001b[0m | \u001b[0m61.61    \u001b[0m | \u001b[0m0.2635   \u001b[0m | \u001b[0m2.602    \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m0.1462   \u001b[0m | \u001b[0m6.23     \u001b[0m | \u001b[0m126.9    \u001b[0m | \u001b[0m91.31    \u001b[0m | \u001b[0m4.715    \u001b[0m | \u001b[0m2.5      \u001b[0m | \u001b[0m2.869    \u001b[0m | \u001b[0m0.3248   \u001b[0m | \u001b[0m0.3416   \u001b[0m | \u001b[0m35.08    \u001b[0m | \u001b[0m0.0409   \u001b[0m | \u001b[0m13.15    \u001b[0m | \u001b[0m0.8943   \u001b[0m | \u001b[0m1.402    \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m0.1399   \u001b[0m | \u001b[0m6.478    \u001b[0m | \u001b[0m38.38    \u001b[0m | \u001b[0m64.95    \u001b[0m | \u001b[0m3.039    \u001b[0m | \u001b[0m2.429    \u001b[0m | \u001b[0m1.861    \u001b[0m | \u001b[0m0.04978  \u001b[0m | \u001b[0m0.1877   \u001b[0m | \u001b[0m38.55    \u001b[0m | \u001b[0m0.01003  \u001b[0m | \u001b[0m36.95    \u001b[0m | \u001b[0m0.284    \u001b[0m | \u001b[0m3.379    \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.63     \u001b[0m | \u001b[0m36.4     \u001b[0m | \u001b[0m40.7     \u001b[0m | \u001b[0m4.083    \u001b[0m | \u001b[0m1.281    \u001b[0m | \u001b[0m1.177    \u001b[0m | \u001b[0m0.1119   \u001b[0m | \u001b[0m0.1618   \u001b[0m | \u001b[0m49.19    \u001b[0m | \u001b[0m0.0508   \u001b[0m | \u001b[0m13.79    \u001b[0m | \u001b[0m0.5235   \u001b[0m | \u001b[0m2.012    \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.253    \u001b[0m | \u001b[0m29.59    \u001b[0m | \u001b[0m51.18    \u001b[0m | \u001b[0m4.806    \u001b[0m | \u001b[0m2.122    \u001b[0m | \u001b[0m1.774    \u001b[0m | \u001b[0m0.2436   \u001b[0m | \u001b[0m0.2979   \u001b[0m | \u001b[0m25.61    \u001b[0m | \u001b[0m0.05071  \u001b[0m | \u001b[0m76.79    \u001b[0m | \u001b[0m0.275    \u001b[0m | \u001b[0m2.154    \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m0.1404   \u001b[0m | \u001b[0m4.761    \u001b[0m | \u001b[0m38.78    \u001b[0m | \u001b[0m69.41    \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m2.815    \u001b[0m | \u001b[0m2.725    \u001b[0m | \u001b[0m0.2019   \u001b[0m | \u001b[0m0.3211   \u001b[0m | \u001b[0m48.12    \u001b[0m | \u001b[0m0.02847  \u001b[0m | \u001b[0m59.03    \u001b[0m | \u001b[0m0.9312   \u001b[0m | \u001b[0m5.256    \u001b[0m |\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.151    \u001b[0m | \u001b[0m89.87    \u001b[0m | \u001b[0m84.81    \u001b[0m | \u001b[0m3.912    \u001b[0m | \u001b[0m3.724    \u001b[0m | \u001b[0m1.519    \u001b[0m | \u001b[0m0.3778   \u001b[0m | \u001b[0m0.1719   \u001b[0m | \u001b[0m14.12    \u001b[0m | \u001b[0m0.01081  \u001b[0m | \u001b[0m15.77    \u001b[0m | \u001b[0m0.2248   \u001b[0m | \u001b[0m4.505    \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.631    \u001b[0m | \u001b[0m96.77    \u001b[0m | \u001b[0m91.29    \u001b[0m | \u001b[0m3.893    \u001b[0m | \u001b[0m2.698    \u001b[0m | \u001b[0m1.438    \u001b[0m | \u001b[0m0.2498   \u001b[0m | \u001b[0m0.3106   \u001b[0m | \u001b[0m33.22    \u001b[0m | \u001b[0m0.03829  \u001b[0m | \u001b[0m95.38    \u001b[0m | \u001b[0m0.3082   \u001b[0m | \u001b[0m4.566    \u001b[0m |\n",
      "| \u001b[95m99       \u001b[0m | \u001b[95m0.1572   \u001b[0m | \u001b[95m6.145    \u001b[0m | \u001b[95m41.11    \u001b[0m | \u001b[95m110.2    \u001b[0m | \u001b[95m4.681    \u001b[0m | \u001b[95m3.995    \u001b[0m | \u001b[95m2.48     \u001b[0m | \u001b[95m0.009723 \u001b[0m | \u001b[95m0.1074   \u001b[0m | \u001b[95m24.39    \u001b[0m | \u001b[95m0.004334 \u001b[0m | \u001b[95m83.08    \u001b[0m | \u001b[95m0.101    \u001b[0m | \u001b[95m4.765    \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m4.357    \u001b[0m | \u001b[0m114.7    \u001b[0m | \u001b[0m73.35    \u001b[0m | \u001b[0m4.261    \u001b[0m | \u001b[0m2.826    \u001b[0m | \u001b[0m2.001    \u001b[0m | \u001b[0m0.03568  \u001b[0m | \u001b[0m0.1521   \u001b[0m | \u001b[0m20.37    \u001b[0m | \u001b[0m0.09659  \u001b[0m | \u001b[0m38.77    \u001b[0m | \u001b[0m0.2315   \u001b[0m | \u001b[0m1.537    \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m3.656    \u001b[0m | \u001b[0m47.31    \u001b[0m | \u001b[0m86.36    \u001b[0m | \u001b[0m4.785    \u001b[0m | \u001b[0m1.198    \u001b[0m | \u001b[0m1.292    \u001b[0m | \u001b[0m0.1305   \u001b[0m | \u001b[0m0.3852   \u001b[0m | \u001b[0m30.24    \u001b[0m | \u001b[0m0.06357  \u001b[0m | \u001b[0m61.75    \u001b[0m | \u001b[0m0.623    \u001b[0m | \u001b[0m6.707    \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.285    \u001b[0m | \u001b[0m40.0     \u001b[0m | \u001b[0m58.45    \u001b[0m | \u001b[0m4.322    \u001b[0m | \u001b[0m1.675    \u001b[0m | \u001b[0m2.322    \u001b[0m | \u001b[0m0.1686   \u001b[0m | \u001b[0m0.2041   \u001b[0m | \u001b[0m12.02    \u001b[0m | \u001b[0m0.03013  \u001b[0m | \u001b[0m41.9     \u001b[0m | \u001b[0m0.9176   \u001b[0m | \u001b[0m1.755    \u001b[0m |\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m6.534    \u001b[0m | \u001b[0m79.95    \u001b[0m | \u001b[0m116.7    \u001b[0m | \u001b[0m3.648    \u001b[0m | \u001b[0m3.979    \u001b[0m | \u001b[0m1.286    \u001b[0m | \u001b[0m0.04159  \u001b[0m | \u001b[0m0.1087   \u001b[0m | \u001b[0m49.68    \u001b[0m | \u001b[0m0.08634  \u001b[0m | \u001b[0m46.56    \u001b[0m | \u001b[0m0.03431  \u001b[0m | \u001b[0m6.036    \u001b[0m |\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m2.024    \u001b[0m | \u001b[0m31.13    \u001b[0m | \u001b[0m45.38    \u001b[0m | \u001b[0m4.744    \u001b[0m | \u001b[0m2.323    \u001b[0m | \u001b[0m1.282    \u001b[0m | \u001b[0m0.2093   \u001b[0m | \u001b[0m0.4745   \u001b[0m | \u001b[0m37.96    \u001b[0m | \u001b[0m0.0964   \u001b[0m | \u001b[0m31.31    \u001b[0m | \u001b[0m0.3858   \u001b[0m | \u001b[0m1.109    \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m1.48     \u001b[0m | \u001b[0m54.88    \u001b[0m | \u001b[0m112.6    \u001b[0m | \u001b[0m4.259    \u001b[0m | \u001b[0m1.025    \u001b[0m | \u001b[0m2.968    \u001b[0m | \u001b[0m0.4681   \u001b[0m | \u001b[0m0.2999   \u001b[0m | \u001b[0m17.39    \u001b[0m | \u001b[0m0.06249  \u001b[0m | \u001b[0m24.41    \u001b[0m | \u001b[0m0.1735   \u001b[0m | \u001b[0m2.64     \u001b[0m |\n",
      "=====================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize the optimizer\n",
    "cnn_bo_optimizer = BayesianOptimization(text_num_cnn, params_cnn, random_state=111)\n",
    "\n",
    "# Run the optimizer\n",
    "cnn_bo_optimizer.maximize(n_iter=100)\n",
    "\n",
    "# # Print the best result\n",
    "# print(cnn_bo_optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f560c58-ff4c-4d81-8036-78b9a713a8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.15715823466092574, 'params': {'activation': 6.144992430691681, 'batch_size': 41.108919894277264, 'conv_filters': 110.20823858391267, 'conv_kernel_size': 4.681361698460874, 'conv_layers': 3.9953514753525634, 'dense_layers': 2.4804188434742707, 'dropout': 0.009722558954651683, 'dropout_rate': 0.10735259626754301, 'epochs': 24.391264529856464, 'learning_rate': 0.004333651471070642, 'neurons': 83.07749075522084, 'normalization': 0.10104973789839489, 'optimizer': 4.764720919234766}}\n"
     ]
    }
   ],
   "source": [
    "# # Print the best result\n",
    "print(cnn_bo_optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7781dd1d-2fd5-4a5f-b724-7313426592a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the results\n",
    "results = cnn_bo_optimizer.res\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "results_df.to_csv('cnn_bayesian_optimization_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b97ec14a-8c38-4ab9-b01f-2dbee2c96f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Extract the best result\n",
    "best_result = cnn_bo_optimizer.max\n",
    "\n",
    "# Save the best result to a JSON file\n",
    "with open('cnn_best_result.json', 'w') as f:\n",
    "    json.dump(best_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3067fa5c-0dbc-4575-bfae-90093708a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(int(round(6.144992430691681)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc69706-9e5e-4405-b81e-00558cf7c012",
   "metadata": {},
   "source": [
    "# Model Test with Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc388618-6906-4257-ba6e-0f7cba6a89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_metrics(history):\n",
    "    metrics = ['accuracy', 'loss', 'recall', 'Precision', 'FalseNegatives']\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for i, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        plt.plot(history.history[metric], label='Training ' + metric)\n",
    "        plt.plot(history.history['val_' + metric], label='Validation ' + metric)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "        plt.title(metric.capitalize() + ' over Epochs')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a4789f3-7c2e-4406-9b1f-ac2cb1ce41e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - FalseNegatives: 538.8587 - Precision: 0.3681 - accuracy: 0.6045 - loss: 0.7129 - recall: 0.2047 - val_FalseNegatives: 337.0000 - val_Precision: 0.0000e+00 - val_accuracy: 0.6372 - val_loss: 0.6372 - val_recall: 0.0000e+00\n",
      "Epoch 2/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - FalseNegatives: 506.1087 - Precision: 0.6084 - accuracy: 0.6787 - loss: 0.6136 - recall: 0.1618 - val_FalseNegatives: 226.0000 - val_Precision: 0.7400 - val_accuracy: 0.7147 - val_loss: 0.5482 - val_recall: 0.3294\n",
      "Epoch 3/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - FalseNegatives: 407.7717 - Precision: 0.5381 - accuracy: 0.6735 - loss: 0.6048 - recall: 0.3747 - val_FalseNegatives: 198.0000 - val_Precision: 0.7433 - val_accuracy: 0.7352 - val_loss: 0.5415 - val_recall: 0.4125\n",
      "Epoch 4/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - FalseNegatives: 309.2065 - Precision: 0.6715 - accuracy: 0.7534 - loss: 0.5296 - recall: 0.5317 - val_FalseNegatives: 239.0000 - val_Precision: 0.7656 - val_accuracy: 0.7104 - val_loss: 0.5412 - val_recall: 0.2908\n",
      "Epoch 5/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - FalseNegatives: 296.2174 - Precision: 0.6466 - accuracy: 0.7370 - loss: 0.5322 - recall: 0.5280 - val_FalseNegatives: 228.0000 - val_Precision: 0.7676 - val_accuracy: 0.7191 - val_loss: 0.5345 - val_recall: 0.3234\n",
      "Epoch 6/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - FalseNegatives: 286.9022 - Precision: 0.6732 - accuracy: 0.7507 - loss: 0.5180 - recall: 0.5577 - val_FalseNegatives: 225.0000 - val_Precision: 0.7619 - val_accuracy: 0.7201 - val_loss: 0.5976 - val_recall: 0.3323\n",
      "Epoch 7/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 304.9891 - Precision: 0.6434 - accuracy: 0.7386 - loss: 0.5294 - recall: 0.5343 - val_FalseNegatives: 84.0000 - val_Precision: 0.6606 - val_accuracy: 0.7696 - val_loss: 0.4844 - val_recall: 0.7507\n",
      "Epoch 8/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - FalseNegatives: 276.0869 - Precision: 0.6449 - accuracy: 0.7550 - loss: 0.4992 - recall: 0.5648 - val_FalseNegatives: 47.0000 - val_Precision: 0.6029 - val_accuracy: 0.7438 - val_loss: 0.5156 - val_recall: 0.8605\n",
      "Epoch 9/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 264.7174 - Precision: 0.6526 - accuracy: 0.7655 - loss: 0.4846 - recall: 0.5899 - val_FalseNegatives: 50.0000 - val_Precision: 0.6119 - val_accuracy: 0.7503 - val_loss: 0.5136 - val_recall: 0.8516\n",
      "Epoch 10/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 235.9239 - Precision: 0.6470 - accuracy: 0.7650 - loss: 0.4917 - recall: 0.6433 - val_FalseNegatives: 245.0000 - val_Precision: 0.8142 - val_accuracy: 0.7137 - val_loss: 0.5281 - val_recall: 0.2730\n",
      "Epoch 11/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 257.9565 - Precision: 0.6598 - accuracy: 0.7627 - loss: 0.4976 - recall: 0.5699 - val_FalseNegatives: 103.0000 - val_Precision: 0.7027 - val_accuracy: 0.7826 - val_loss: 0.5148 - val_recall: 0.6944\n",
      "Epoch 12/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - FalseNegatives: 262.8696 - Precision: 0.7089 - accuracy: 0.7759 - loss: 0.4772 - recall: 0.5706 - val_FalseNegatives: 139.0000 - val_Precision: 0.7557 - val_accuracy: 0.7815 - val_loss: 0.4659 - val_recall: 0.5875\n",
      "Epoch 13/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - FalseNegatives: 254.4783 - Precision: 0.6774 - accuracy: 0.7663 - loss: 0.4971 - recall: 0.6144 - val_FalseNegatives: 73.0000 - val_Precision: 0.6804 - val_accuracy: 0.7879 - val_loss: 0.4738 - val_recall: 0.7834\n",
      "Epoch 14/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - FalseNegatives: 243.6087 - Precision: 0.6738 - accuracy: 0.7693 - loss: 0.4698 - recall: 0.6123 - val_FalseNegatives: 135.0000 - val_Precision: 0.7426 - val_accuracy: 0.7793 - val_loss: 0.4563 - val_recall: 0.5994\n",
      "Epoch 15/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 235.7283 - Precision: 0.6606 - accuracy: 0.7654 - loss: 0.4642 - recall: 0.6025 - val_FalseNegatives: 121.0000 - val_Precision: 0.7606 - val_accuracy: 0.7966 - val_loss: 0.4446 - val_recall: 0.6409\n",
      "Epoch 16/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 223.4674 - Precision: 0.7087 - accuracy: 0.7928 - loss: 0.4404 - recall: 0.6480 - val_FalseNegatives: 79.0000 - val_Precision: 0.7011 - val_accuracy: 0.7966 - val_loss: 0.4391 - val_recall: 0.7656\n",
      "Epoch 17/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - FalseNegatives: 209.5652 - Precision: 0.6835 - accuracy: 0.7881 - loss: 0.4533 - recall: 0.6878 - val_FalseNegatives: 116.0000 - val_Precision: 0.7517 - val_accuracy: 0.7966 - val_loss: 0.4355 - val_recall: 0.6558\n",
      "Epoch 18/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - FalseNegatives: 222.6630 - Precision: 0.7190 - accuracy: 0.7970 - loss: 0.4295 - recall: 0.6498 - val_FalseNegatives: 136.0000 - val_Precision: 0.7913 - val_accuracy: 0.7966 - val_loss: 0.4408 - val_recall: 0.5964\n",
      "Epoch 19/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 187.4239 - Precision: 0.7422 - accuracy: 0.8187 - loss: 0.4132 - recall: 0.7073 - val_FalseNegatives: 37.0000 - val_Precision: 0.6316 - val_accuracy: 0.7718 - val_loss: 0.4814 - val_recall: 0.8902\n",
      "Epoch 20/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - FalseNegatives: 204.1196 - Precision: 0.7077 - accuracy: 0.8016 - loss: 0.4042 - recall: 0.7013 - val_FalseNegatives: 38.0000 - val_Precision: 0.6416 - val_accuracy: 0.7793 - val_loss: 0.4577 - val_recall: 0.8872\n",
      "Epoch 21/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - FalseNegatives: 213.9783 - Precision: 0.6948 - accuracy: 0.7947 - loss: 0.4268 - recall: 0.7113 - val_FalseNegatives: 50.0000 - val_Precision: 0.6674 - val_accuracy: 0.7922 - val_loss: 0.4705 - val_recall: 0.8516\n",
      "Epoch 22/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 179.7500 - Precision: 0.7593 - accuracy: 0.8302 - loss: 0.3859 - recall: 0.7273 - val_FalseNegatives: 148.0000 - val_Precision: 0.8077 - val_accuracy: 0.7922 - val_loss: 0.4342 - val_recall: 0.5608\n",
      "Epoch 23/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - FalseNegatives: 157.3804 - Precision: 0.8091 - accuracy: 0.8531 - loss: 0.3578 - recall: 0.7498 - val_FalseNegatives: 148.0000 - val_Precision: 0.7975 - val_accuracy: 0.7890 - val_loss: 0.5037 - val_recall: 0.5608\n",
      "Epoch 24/24\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - FalseNegatives: 175.6956 - Precision: 0.7458 - accuracy: 0.8263 - loss: 0.3853 - recall: 0.7376 - val_FalseNegatives: 188.0000 - val_Precision: 0.8563 - val_accuracy: 0.7707 - val_loss: 0.4828 - val_recall: 0.4421\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[1;32m     48\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(score)\n\u001b[1;32m     51\u001b[0m cv_score \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataframe(score)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/scikeras/wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neurons = 83.07749075522084\n",
    "activation= 6.144992430691681\n",
    "batch_size = 41.108919894277264\n",
    "conv_filters = 110.20823858391267\n",
    "conv_kernel_size = 4.681361698460874\n",
    "conv_layers = 3.9953514753525634\n",
    "dense_layers = 2.4804188434742707\n",
    "dropout = 0.009722558954651683\n",
    "normalization = 0.10104973789839489\n",
    "learning_rate = 0.004333651471070642\n",
    "optimizer = Adam(learning_rate = learning_rate)\n",
    "epochs = 24.391264529856464\n",
    "dropout_rate = 0.10735259626754301\n",
    "\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential']\n",
    "activation = activationL[int(round(activation))]\n",
    "\n",
    "# Round numerical parameters\n",
    "neurons = int(round(neurons))\n",
    "batch_size = int(round(batch_size))\n",
    "epochs = int(round(epochs))\n",
    "conv_layers = int(round(conv_layers))\n",
    "conv_filters = int(round(conv_filters))\n",
    "conv_kernel_size = int(round(conv_kernel_size))\n",
    "dense_layers = int(round(dense_layers))\n",
    "\n",
    "model = cnn_model(\n",
    "            neurons=neurons,\n",
    "            activation=activation,\n",
    "            optimizer=optimizer,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            conv_layers=conv_layers,\n",
    "            conv_filters=conv_filters,\n",
    "            conv_kernel_size=conv_kernel_size,\n",
    "            dense_layers=dense_layers,\n",
    "            normalization=normalization,\n",
    "            dropout=dropout,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "history = model.fit(X_train, y_train, validation_split = 0.2, batch_size = batch_size, epochs = epochs)\n",
    "\n",
    "# Create KerasClassifier\n",
    "keras_clf = KerasClassifier(build_fn=model,optimizer=optimizer, batch_size = batch_size, epochs = epochs, verbose=0)\n",
    "\n",
    "# Perform cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "score = cross_val_score(keras_clf, X_train, y_train, scoring='accuracy', cv=kfold)\n",
    "score = np.nan_to_num(score)\n",
    "cv_score = pd.Dataframe(score)\n",
    "display(cv_score)\n",
    "# history = model.fit(X_train, y_train, validation_split = 0.2, batch_size = batch_size, epochs = epochs)\n",
    "# plot_all_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b0e85-2d3a-4bfd-b27b-905d7fa1c9d6",
   "metadata": {},
   "source": [
    "## Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7aa1c1-c2ff-47cd-bde6-9d43240fa46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluation_results = model.evaluate(X_train, y_train)\n",
    "# print(f'Evaluation Results: {evaluation_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfdc0d90-33d5-40be-80fd-7f8c4d15d175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 229.2449 - Precision: 0.8410 - accuracy: 0.8592 - loss: 0.3509 - recall: 0.7114\n",
      "Test loss: 0.3679976165294647\n",
      "Test accuracy: 0.8474466800689697\n",
      "Test recall: 0.6987951993942261\n",
      "Test precision: 0.8254681825637817\n",
      "Test false negatives: 475.0\n"
     ]
    }
   ],
   "source": [
    "train_evaluation_results = model.evaluate(X_train, y_train)\n",
    "train_loss = train_evaluation_results[0]\n",
    "train_accuracy = train_evaluation_results[1]\n",
    "train_recall = train_evaluation_results[2]\n",
    "train_precision = train_evaluation_results[3]\n",
    "train_false_negatives = train_evaluation_results[4]\n",
    "\n",
    "print(f'Test loss: {train_loss}')\n",
    "print(f'Test accuracy: {train_accuracy}')\n",
    "print(f'Test recall: {train_recall}')\n",
    "print(f'Test precision: {train_precision}')\n",
    "print(f'Test false negatives: {train_false_negatives}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "794dc8cf-3ae4-4304-8547-0e3befd832bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy %: 84.74\n",
      "Training Set Recall %: 69.88\n",
      "Training Set Precision %: 82.55\n"
     ]
    }
   ],
   "source": [
    "train_acc_perc = round((train_accuracy * 100), 2)\n",
    "train_recall_perc = round((train_recall * 100), 2)\n",
    "train_precision_perc = round((train_precision * 100), 2)\n",
    "\n",
    "print(f\"Training Set Accuracy %: {train_acc_perc}\")\n",
    "print(f'Training Set Recall %: {train_recall_perc}')\n",
    "print(f'Training Set Precision %: {train_precision_perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f214f17b-7708-409e-af39-fe57417c5933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step\n",
      "Number of predictions made by the model: 4641\n"
     ]
    }
   ],
   "source": [
    "#make prediction \n",
    "train_preds = np.round(model.predict(X_train))\n",
    "print('Number of predictions made by the model: {}'.format(len(train_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d68f5651-2e4d-4fb5-a923-a5d38e01efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8228610675039246\n",
      "Macro F1 %: 82.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "train_macrof1_score = f1_score(y_train, train_preds, average='macro')\n",
    "train_macro_perc = round((train_macrof1_score * 100), 2)\n",
    "print(train_macrof1_score)\n",
    "\n",
    "print(f'Macro F1 %: {train_macro_perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79c841bc-8a68-49d6-b04b-6e6c72e36277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440055396630334\n",
      "Macro F1 %: 84.4\n"
     ]
    }
   ],
   "source": [
    "train_wf1_score = f1_score(y_train, train_preds, average='weighted')\n",
    "train_weighted_perc = round((train_wf1_score * 100), 2)\n",
    "print(train_wf1_score)\n",
    "\n",
    "print(f'Macro F1 %: {train_weighted_perc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf05ce-1ecf-4896-8fcb-b3d9002e1119",
   "metadata": {},
   "source": [
    "## Testing Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "224da2dd-eb9b-4691-b997-31d791c8a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - FalseNegatives: 91.8684 - Precision: 0.6903 - accuracy: 0.7747 - loss: 0.4722 - recall: 0.5654\n",
      "Evaluation Results: [0.4687822759151459, 0.776055097579956, 0.5873417854309082, 0.7051671743392944, 163.0]\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = model.evaluate(X_test, y_test)\n",
    "print(f'Evaluation Results: {evaluation_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "239e729a-458c-4f9a-ae8f-e04862fee748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - FalseNegatives: 229.2449 - Precision: 0.8410 - accuracy: 0.8592 - loss: 0.3509 - recall: 0.7114\n",
      "Test loss: 0.4687822759151459\n",
      "Test accuracy: 0.776055097579956\n",
      "Test recall: 0.5873417854309082\n",
      "Test precision: 0.7051671743392944\n",
      "Test false negatives: 163.0\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = model.evaluate(X_test, y_test)\n",
    "test_loss = evaluation_results[0]\n",
    "test_accuracy = evaluation_results[1]\n",
    "test_recall = evaluation_results[2]\n",
    "test_precision = evaluation_results[3]\n",
    "test_false_negatives = evaluation_results[4]\n",
    "\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "print(f'Test recall: {test_recall}')\n",
    "print(f'Test precision: {test_precision}')\n",
    "print(f'Test false negatives: {test_false_negatives}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a35e5c71-a480-48a1-a394-ca04e280f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy %: 77.61\n",
      "Training Set Recall %: 58.73\n",
      "Training Set Precision %: 70.52\n"
     ]
    }
   ],
   "source": [
    "test_acc_perc = round((test_accuracy * 100), 2)\n",
    "test_recall_perc = round((test_recall * 100), 2)\n",
    "test_precision_perc = round((test_precision * 100), 2)\n",
    "\n",
    "print(f\"Training Set Accuracy %: {train_acc_perc}\")\n",
    "print(f'Training Set Recall %: {train_recall_perc}')\n",
    "print(f'Training Set Precision %: {train_precision_perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73955247-8bfd-4563-8e2b-da083271518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "Number of predictions made by the model: 1161\n",
      "0.7390902993382613\n",
      "Macro F1 %: 73.91\n",
      "0.7704723365935497\n",
      "weighted F1 %: 77.05\n"
     ]
    }
   ],
   "source": [
    "#make prediction \n",
    "test_preds = np.round(model.predict(X_test))\n",
    "print('Number of predictions made by the model: {}'.format(len(test_preds)))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "test_macrof1_score = f1_score(y_test, test_preds, average='macro')\n",
    "test_macro_perc = round((test_macrof1_score * 100), 2)\n",
    "print(test_macrof1_score)\n",
    "\n",
    "print(f'Macro F1 %: {test_macro_perc}')\n",
    "\n",
    "test_wf1_score = f1_score(y_test, test_preds, average='weighted')\n",
    "test_weighted_perc = round((test_wf1_score * 100), 2)\n",
    "print(test_wf1_score)\n",
    "\n",
    "print(f'weighted F1 %: {test_weighted_perc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b3f0c-6728-4ef1-9062-980641b01fc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c2f44a2-6300-462d-9e84-90da1adab1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<Functional name=functional_35, built=True>' (type <class 'keras.src.models.functional.Functional'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m scoring \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m ]\n\u001b[1;32m      4\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m op_cv_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scores)\n\u001b[1;32m      7\u001b[0m display(op_cv_scores)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/joblib/parallel.py:1844\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;66;03m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[0;32m-> 1844\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1845\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m---> 63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:432\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m--> 432\u001b[0m         \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    433\u001b[0m         X,\n\u001b[1;32m    434\u001b[0m         y,\n\u001b[1;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/base.py:91\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_project_dir/my_project_env/lib/python3.10/site-packages/sklearn/base.py:113\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should provide an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn estimator instead of a class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m             )\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    114\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[1;32m    118\u001b[0m             )\n\u001b[1;32m    120\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m    121\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<Functional name=functional_35, built=True>' (type <class 'keras.src.models.functional.Functional'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['accuracy', 'recall',  'precision','f1_macro', 'f1_weighted' ]\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=kfold)\n",
    "op_cv_scores = pd.DataFrame(scores)\n",
    "display(op_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5a0a2-7ecb-439b-bc32-8f38546ed96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "import keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
